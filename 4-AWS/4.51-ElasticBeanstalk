A developer is creating a React application whose source code is hosted in GitHub. To help ensure proper functionality and identify any UI issues before going live, the developer must perform end-to-end (E2E) testing using Cypress.

Which combination of actions should the developer take? (Select Two)


Include the location of the Cypress configuration file in the aws-exports.js file.

Connect the Github repository to AWS Amplify Hosting````````````````


Create an application in AWS Amplify Studio. Clone the application’s source code in a local environment and run amplify pull --appId APP_ID --envName ENV_NAME

Update the amplifyconfiguration.json with appropriate configuration settings for Cypress.

Update the amplify.yml file with appropriate configuration settings for Cypress.```````````



// Correct
// AWS Amplify is a set of purpose-built tools and features that enables frontend web and mobile developers to quickly and easily build full-stack applications on AWS.

// Amplify provides two services:

// -Amplify Hosting – provides a git-based workflow for hosting full-stack serverless web apps with continuous deployment.

// -Amplify Studio – a visual development environment that simplifies the creation of scalable, full-stack web and mobile apps. Use can use Amplify Studio to build your frontend UI with a set of ready-to-use UI components, create an app backend with AWS resources, and then connect the two together.

// Amplify Hosting provides deep integration with Cypress for End-to-End (E2E) testing, allowing developers to generate a UI report for their tests. To add Cypress tests to your application, you can update the build settings in the amplify.yml configuration file, which will enable Amplify to run the tests during the build process.


==========================================================================




Amazon Lightsail - FOR NOOBS.

With a virtual private server (VPS), also known as an instance, users can run websites and web applications in a highly secure and available environment. Lightsail is a VPS provider and is a useful way to get started with AWS for users who need a solution to build and host their applications on AWS Cloud.

Lightsail provides developers with compute, storage, and networking capacity and capabilities to deploy and manage websites and web applications in the cloud. Lightsail includes everything you need to launch your project quickly for a low, predictable monthly price. This includes VMs, containers, databases, content delivery network (CDN), load balancers, Domain Name System (DNS) management, and so on. 

So what is the difference between Amazon EC2 and Lightsail? Lightsail provides low-cost, pre-configured cloud resources for simple workloads just starting on AWS. Amazon EC2 is a compute web service that provides secure, resizable compute in the cloud. It has far greater scale and optimization capabilities than Lightsail.
==========================================================================
AWS Batch

Batch computing is defined as the running of a program without manual intervention. The program's input parameters are predefined through scripts, command-line arguments, control files, or job control language. A given batch job might depend on the completion of preceding jobs or on the availability of certain inputs. This makes the sequencing and scheduling of multiple jobs critical.

AWS Batch is a set of batch management capabilities that you can use to efficiently run hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions the optimal quantity and type of compute resources, such as CPU- or memory-optimized compute resources, based on the volume and specific resource requirements of the batch jobs submitted. AWS Batch plans, schedules, and runs your batch computing workloads using Amazon EC2 and AWS compute resources with Fargate or Fargate Spot. 
===========================================================================
AWS Elastic Beanstalk

With Elastic Beanstalk, developers upload their application. Then, Elastic Beanstalk automatically handles the deployment details of capacity provisioning, load balancing, auto-scaling, and application health monitoring. By using Elastic Beanstalk, developers can focus on developing their application and are freed from deployment-oriented tasks, such as provisioning servers, setting up load balancing, or managing scaling. 

Elastic Beanstalk automatically scales your application up and down based on your application's specific need using adjustable Auto Scaling settings. For example, you can use CPU utilization metrics to invoke Auto Scaling actions. With Elastic Beanstalk, your application can handle peaks in workload or traffic while minimizing your costs.



AWS OpsWork and elastic Beanstalk are AWS CONFIGURATION AS CODE solutions
"AWS OpsWork" - chef/puppet/ansible
AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers. OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises compute environments. OpsWorks has three offerings, AWS Opsworks for Chef Automate, AWS OpsWorks for Puppet Enterprise, and AWS OpsWorks Stacks.


"ELASTIC BEANSTALK"
Platform as a Service
create infrastructure for you
its handles:
infrastructure 
capacity provisioning
load balancing
auto-scaling
application platform and updates 
you still have complete admin control
You can run Containers on EB, either in single-container or multi-container, these containers are running on ECS instead of EC2

ENVIRONMENTS:
    Web Environments:
        Single-Instance:
        Load-Balanced: launch EC2s behind an ELB managed by an ASG (autosc)
    Worker Environment:
        Creates an SQS Queue, install the SQS daemon on the EC2 instances.
        Has ASG scaling policy which will add or remove instances based on queue size



no additional charges for beanstalk, only charged for resources you use
"Deployment Updates"
All At Once: involves service interruption, good for testing environment
rolling back requires a further all at once update 

Rolling: reduced capacity during deployment, deploys upgrade in batches
rolling back requires a further rolling update 

Rolling With Additional Batch: maintains full capacity, new updated batch of instances is created, traffic shifts and another batch is updated
rolling back requires a further rolling update -it takes time
not for critical application

Immutable: maintain full capacity, preferred for mission critical systems
rolling back requires deleting new instance

Traffic Splitting: performs immutable deployments and splits traffic b/w old and new deployment, enabling canary Testing (coalmines, CO canary bird)

Blue/green deployment is at DNS level, not EB level.
       ================= EB Environment
      =       __ec2    =
      =      |         =
      =      |         =
r53 --= elb--^--rds    =    This is in-place immutable
      =      |         =
      =      |         =
      =      ----ec2   =
      =                =
       =================
Deciding factor is mainly the database. if you are running db in an instance inside ENV, it will be terminated too. So, its better to go with blue/green deploy with your database outside of it in rds

            ================= EB Environment
            =       __ec2    =
     rds    =      |         =
      |     =      |         =
r53 --X-----= elb--^         =  This is blue/green
      |      =                = swap ENV URL
      |      =                =
      |      =                =
      |      =                =
      |       =================
      |
      |     ================= EB Environment
      |     =       __ec2    =
      |     =      |         =
      |     =      |         =
r53 --------= elb--^         =
            =                =
            =                =
            =                =
            =                =
             =================

Advanced Elastic Beanstalk Update Setting:
"for instances using Amazon Linux 1":
create .ebextensions folder in root dir of source code 
files you want to run along with code must have .config extension 

"for instances running Amazon Linux 2":
Create a BuildFile for scripts (yaml/json)
in the root directory of your application source
for commands that exit upon completion like shells scripts.
Example Buildfile
                    make: ./build.sh
If you want to provide custom build steps, we recommend that you use predeploy platform hooks for anything but the simplest commands, instead of a Buildfile. Platform hooks allow richer scripts and better error handling. Platform hooks are described in the next section.
------------------------------------
With ElasticBeanstalk, you can:

– Select the operating system that matches your application requirements (e.g., Amazon Linux or Windows Server 2016)

– Choose from several Amazon EC2 instances, including On-Demand, Reserved Instances, and Spot Instances.

– Choose from several available database and storage options.

– Enable login access to Amazon EC2 instances for immediate and direct troubleshooting

– Quickly improve application reliability by running in more than one Availability Zone.

– Enhance application security by enabling HTTPS protocol on the load balancer

– Access built-in Amazon CloudWatch monitoring and getting notifications on application health and other important events

– Adjust application server settings (e.g., JVM settings) and pass environment variables

– Run other application components, such as a memory caching service, side-by-side in Amazon EC2.

– Access log files without logging in to the application servers
------------------------------------
Create a ProcFile for long running processes.
For example, custom commands to start up your application.
Use a Procfile for long-running application processes that shouldn't exit. Elastic Beanstalk expects processes run from the Procfile to run continuously. Elastic Beanstalk monitors these processes and restarts any process that terminates.'

All paths in the Procfile are relative to the root of the source bundle. The following example Procfile defines three processes. The first one, called web in the example, is the main web application.

Example Procfile
web: bin/myserver
cache: bin/mycache
foo: bin/fooapp
Elastic Beanstalk configures the proxy server to forward requests to your main web application on port 5000, and you can configure this port number. A common use for a Procfile is to pass this port number to your application as a command argument. 
------------------------------------
Create PlatformHooks for custom scripts or executables
that run at various stages
when your EC2 instances are being provisioned,
and use a folder structure like this
            .platform/hooks/prebuild
            .platform/hooks/predeploy
            .platform/hooks/postdeploy
to organize and store your scripts.

-------------------------------------
You can
launch RDS within Elastic Beanstalk 
issue: if you terminate your environment, your database is also gone 
    good tfor test environment 

launch RDS outside Elastic Beanstalk 
preferred approach for production systems 
how: 
1-add an additional security group to your env AutoScaling group to allow EC2 instances to communite with DB on relevant port e.g. 3306 for mySQL 

2-provide connection string information to your app servers using EB env properties
ARN for RDS database and db password (min) added to .....
EB->ENV->configuration->Env Properties->add DB connection parameters
key             value 
RDS_HOSTNAME    mysql-instance324324324.us-east-1.rds.amazonaws.com

-----------------------------------
Migrating Applications to Elastic Beanstalk 
for .net apps -> Windows Web Application Migration Assistant for EB
interactive powershell utility migrate website from windows servers to aws
open-source tool available on github


2.1. Clone this repository
Use the following:

git clone https://github.com/aws/aws-elastic-beanstalk-cli-setup.git
2.2. Install/Upgrade the EB CLI
MacOS/Linux
On Bash or Zsh:

python ./aws-elastic-beanstalk-cli-setup/scripts/ebcli_installer.py







---------------------------------------------------------------------------
-------------BIG LAB with Cloud 9------------------------------------------
Make a Project
https://github.com/ExamProCo/TheFreeAWSDeveloperAssociate/tree/master/study-sync-000

Cloud9 -> Create Environment


npm i c9 -g
    4  c9 README.md 
    5  mkdir ~/environment/study-sync
    6  cd study-sync/
    7  npm init -y
    8  npm i express --save
    9  touch index.html index.js app.js style.css
   11  curl -s http://169.254.169.254/latest/meta-data
   12  curl -s http://169.254.169.254/latest/meta-data/mac
   13  curl -s http://169.254.169.254/latest/meta-data/network
   17  curl -s http://169.254.169.254/latest/meta-data/network/interfaces
   18  curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs
   19  curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/06:e1:d0:d1:ed:7c
   curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/06:e1:d0:d1:ed:7c/security-group-ids                                                 
   24  aws ec2 authorize-security-group-ingress help
   25  aws ec2 authorize-security-group-ingress --group-id sg-063e5deb3f09c6e44 --port 8080 --protocol tcp --cidr 119.73.100.57/32
   30  aws ec2 describe-security-groups --group-ids sg-063e5deb3f09c6e44 --output text

 35  curl -s http://169.254.169.254/latest/meta-data/public-ipv4
   36  PORT=8080 npm start
   37  touch .gitignore
   38  ls -alh
   39  c9 .gitignore 
   40  git init
   41  ls -la
   42  git status
   43  git add .
   44  git status
   45  git commit -m "initial Commit"
   46  cd ..
   47  git clone https://github.com/aws/aws-elastic-beanstalk-cli-setup.git
   48  ll
# install elastic beanstalk to our instance
   50  python ./aws-elastic-beanstalk-cli-setup/scripts/ebcli_installer.py
   51  eb
   52  echo 'export PATH="/home/ec2-user/.ebcli-virtual-env/executables:$PATH"' >> ~/.bash_profile && source ~/.bash_profile
   53  eb
   54  ls -la
   55  rm -rf aws-elastic-beanstalk-cli-setup/
   58  cd study-sync/
   66  mkdir .ebextensions
   67  touch .ebextensions/001_envar.config
   68  touch .ebextensions/002_node_command.config

   001_envar.config
option_settings:
    aws:elasticbeanstalk:application:environment:
        PORT: 8081
        NODE_ENV: production


   002_node_command.config
option_settings:
    aws:elasticbeanstalk:container:nodejs:
        NodeCommand: "npm start"
        NodeVersion: 16.20.2


# Got Error - This is legacy way 
# new way of telling Elastic Beanstalk what to do with our application 

   75  touch ProcFile   --> web: npm start
   76  git add .
   77  git status
   78  git add .
   79  git commit -m "ProcFile"
   80  git push
   81  eb create --single
Starts Creating EB Environment 
got error = The instance profile aws-elasticbeanstalk-ec2-role associated with the environment does not exist.

solution
If someone don't want or can't to create the role using the aws elb web console, you just need to create the role manually and add these policies:
Open IAM Console → In the navigation pane of the console, choose Roles and then create role → Under Trusted entity type, choose AWS service → Under Use case, choose EC2 → Choose Next → Attach- AWSElasticBeanstalkWebTier, AWSElasticBeanstalkWorkerTier, AWSElasticBeanstalkMulticontainerDocker → Choose Next → Enter a name for the role - aws-elasticbeanstalk-ec2-role → Choose Create role.

If you already have an instance profile, make sure you have below-required policies. To meet the default use cases for an environment, these policies must be attached to the role for the EC2 instance profile:-

Role name: aws-elasticbeanstalk-ec2-role

Permission policies attached:-

AWSElasticBeanstalkWebTier
AWSElasticBeanstalkWorkerTier
AWSElasticBeanstalkMulticontainerDocker
Trust relationship policy for EC2:-

{
  "Version": "2008-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "ec2.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
other inline policies for rupert
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "Stmt1482712489000",
			"Effect": "Allow",
			"Action": [
				"iam:CreateRole",
				"iam:AttachRolePolicy",
				"iam:ListInstanceProfilesForRole",
				"iam:ListInstanceProfiles",
				"iam:CreateInstanceProfile",
				"iam:AddRoleToInstanceProfile"
			],
			"Resource": [
				"*"
			]
		}
	]
}

NOW all policies for Developer group

AmazonEC2FullAccess	AWS managed
AmazonS3FullAccess	AWS managed	
AmazonSSMFullAccess	AWS managed	
AWSCodeCommitFullAccess	AWS managed	
AWSElasticBeanstalkWebTier	AWS managed	
Provide the instances in your web server environment access to upload log files to Amazon S3.
AWSElasticBeanstalkWorkerTier	AWS managed	
Provide the instances in your worker environment access to upload log files to Amazon S3, to use Amazon SQS to monitor your application's job queue, to use Amazon DynamoDB to perform leader election, and to Amazon CloudWatch to publish metrics for health monitoring.'

AWSElasticBeanstalkMulticontainerDocker	AWS managed	
Provide the instances in your multicontainer Docker environment access to use the Amazon EC2 Container Service to manage container deployment tasks.

AWSCloud9Administrator	AWS managed	
Provides administrator access to AWS Cloud9.

AWSCloud9SSMInstanceProfile	AWS managed	
This policy will be used to attach a role on a InstanceProfile which will allow Cloud9 to use the SSM Session Manager to connect to the instance

AdministratorAccess-AWSElasticBeanstalk	AWS managed	
Grants account administrative permissions. Explicitly allows developers and administrators to gain direct access to resources they need to manage AWS Elastic Beanstalk applications


$ eb status

from 
https://docs.aws.amazon.com/elastic-beanstalk/index.html
To perform an immutable update for each deployment with a health check threshold of Warning, and proceed with the deployment even if instances in a batch don't pass health checks within a timeout of 15 minutes, specify the following options and values.'

Example .ebextensions/immutable-ignorehealth.config
option_settings:
  aws:elasticbeanstalk:command:
    DeploymentPolicy: Immutable
    HealthCheckSuccessThreshold: Warning
    IgnoreHealthCheck: true
    Timeout: "900"

---------------------------------------------------------
Blue/green deployments

$ eb clone (clone and starts a new environment)
  109  eb clone
  118  eb swap study-sync-prod --destination_name study-sync-prod-clone
  120  eb swap -h
  121  eb terminate study-sync-prod
  122  eb terminate study-sync-prod-clone

--------------------------------------------------------
  128  touch Dockerfile
  130  touch .dockerignore
  134  eb platform select
  135  docker build --tag study-sync:1.0 .
  136  docker images
  139  curl -s http://169.254.169.254/latest/meta-data
  140  curl -s http://169.254.169.254/latest/meta-data/public-ipv4

eb platform select
Build an image from your Dockerfile
To build you docker image, run the following command in your cloud9 terminal:

docker build --tag study-sync:1.0 .
It will build your image with the commands defined in your Dockerfile and assign a tag to it.

To confirm your image, run the following command:

docker images
Run locally your container
Now your image is created you can locally run your container with the command:



docker run --env PORT=8080 --publish 8080:8080 study-sync:1.0




Dockerfile 
# we'll use 10 since its same as Amazon Linux 1 default node version
FROM node:10
# where our app will be located in the image
RUN mkdir -p /app
WORKDIR /app
# move all source code
COPY . .
RUN npm install
CMD [ "npm", "start" ]
EXPOSE 8080
'
.dockerignore
node_modules


----------------------------------------------------------------
Working with Elastic Container Registry on AWS 
 149  aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 767665886117.dkr.ecr.us-east-1.amazonaws.com 

====================================
IAM > (rupert via developer)
AmazonEC2ContainerRegistryFullAccess 
====================================

aws->ecr->createrepository->study-sync
 $ docker images
 Usage:  docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]
 $ docker tag 4ec7e703029a 767665886117.dkr.ecr.us-east-1.amazonaws.com/study-sync
 $ docker push 767665886117.dkr.ecr.us-east-1.amazonaws.com/study-sync


----------------------------------------------------------------------

Running same Application as new with Dockerrun.aws.json instead of Dockerfile . from saved image in ECR 


mkdir ~/environment/study-syn-external
mkdir ~/environment/study-sync-external/.ebextensions/... (copypaste)
touch .gitignore 
touch ~/environment/study-syn-external/Dockerrun.aws.json


// 1 for single container, version=1 for multi-container
{
    "AWSEBDockerrunVersion": "1",
    "Image": {
        "Name": "767665886117.dkr.ecr.us-east-1.amazonaws.com/study-sync"
    },
    "Ports": {[
        "ContainerPort": 8080,
        "HostPort": 8080
        ]}
}

git init 
add commit
eb init 
git push 
eb create --single


==============================================================================================================
I want to monitor memory use with Amazon CloudWatch from my AWS Elastic Beanstalk environment in Windows.


Short description
You can provision Elastic Beanstalk configuration files (.ebextensions) to monitor memory utilization with CloudWatch for .NET on Windows Server with IIS by doing the following:

Create the .ebextensions directory.
Create and save configuration file in the .ebextensions directory.
Deploy your application and view your metrics.
Note: By default, the unified CloudWatch agent is installed on all Elastic Beanstalk Windows environments running platform versions 2.0.1 or later.

Resolution
Create the .ebextensions directory
In the root of your application bundle, create a hidden directory named .ebextensions.
Example: This example demonstrates an application source bundle structure with .ebextensions directory at the top level of the project directory.

~/workspace/my-application/
|-- Content
|-- .ebextensions
|  
|-- archive.xml
`-- systemInfo.xml
Create and save configuration file in the .ebextensions directory
Create a file called 01_cw-memory-metrics.config inside the .ebextensions directory that you created as part of the application source bundle.
Example: This example extends the CloudWatch agent configuration file - Metrics section.

files:
  "C:\\Program Files\\Amazon\\AmazonCloudWatchAgent\\cw-memory-config.json":
    content: |
{
  "metrics": {
    "append_dimensions": {
      "AutoScalingGroupName": "${aws:AutoScalingGroupName}",
      "ImageId": "${aws:ImageId}",
      "InstanceId": "${aws:InstanceId}",
      "InstanceType": "${aws:InstanceType}"
    },
    "metrics_collected": {
      "Memory": {
        "measurement": [
          "% Committed Bytes In Use"
        ],
        "metrics_collection_interval": 10
      }
    }
  }
}

container_commands:
  01_set_config_and_reinitialize_cw_agent:
    command: powershell.exe cd 'C:\Program Files\Amazon\AmazonCloudWatchAgent'; powershell.exe -ExecutionPolicy Bypass -File ./amazon-cloudwatch-agent-ctl.ps1 -a append-config -m ec2 -c file:cw-memory-config.json -s; powershell.exe -ExecutionPolicy Bypass -File ./amazon-cloudwatch-agent-ctl.ps1 -a start; exit
The 01_cw-memory-metrics.config configuration file does the following:

Defines the metrics that the CloudWatch agent collects and publishes to CloudWatch console - Metrics.
Collects the metrics for percentage of memory used.
The files section includes the CloudWatch agent configuration JSON content that defines which metric to publish to CloudWatch.
The container_commands section runs commands after the application bundle is unpacked on the Amazon Elastic Compute Cloud (Amazon EC2) instance.




================================================================================================================
A developer needs to configure the environment name, solution stack, and environment links of his application environment which will be hosted in Elastic Beanstalk. Which configuration file should the developer add in the source bundle to meet the above requirement?


env.yaml

Dockerrun.aws.json

cron.yaml

env.config
================================================================================================================
A developer is instructed to configure a worker daemon to queue messages based on a specific schedule using a worker environment hosted in Elastic Beanstalk. Periodic tasks should be defined to automatically add jobs to your worker environment’s queue at regular intervals.

Which configuration file should the developer add to the source bundle to meet the above requirement?


appspec.yml

env.yaml

cron.yaml``````````````````````

Dockerrun.aws.json

You can define periodic tasks in a file named cron.yaml in your source bundle to add jobs to your worker environment’s queue automatically at a regular intervals. For example, you can configure and upload a cron.yaml file, which creates two periodic tasks: one that runs every 12 hours and a second that runs at 11 pm UTC every day.

Hence, using the cron.yaml is the correct configuration file to be used in this scenario.

Dockerrun.aws.json is incorrect because this configuration file is primarily used in multi-container Docker environments that are hosted in Elastic Beanstalk. This can be used alone or combined with source code and content in a source bundle to create an environment on a Docker platform.

env.yaml is incorrect because this is primarily used to configure the environment name, solution stack, and environment links to use when creating your environment in Elastic Beanstalk.

appspec.yml is incorrect because this is used to manage each application deployment as a series of lifecycle event hooks in CodeDeploy and not in Elastic Beanstalk.

=================================================================================================================
An application performs various workflows and processes long-running tasks that take a long time to complete. The users are complaining that the application is unresponsive since the workflow substantially increased the time it takes to complete a user request.

Which of the following is the BEST way to improve the performance of the application?

Use an Amazon ECS Cluster with a Fargate launch type to process the tasks asynchronously.
"Use an Elastic Beanstalk worker environment to process the tasks asynchronously."
Use a multicontainer docker environment in Elastic Beanstalk to process the long-running tasks asynchronously.
Spawn a worker process locally in the EC2 instances and process the tasks asynchronously.
Correct
If your application performs operations or workflows that take a long time to complete, you can offload those tasks to a dedicated worker environment. Decoupling your web application front end from a process that performs blocking operations is a common way to ensure that your application stays responsive under load.

A long-running task is anything that substantially increases the time it takes to complete a request, such as processing images or videos, sending emails, or generating a ZIP archive. These operations can take only a second or two to complete, but a delay of a few seconds is a lot for a web request that would otherwise complete in less than 500 ms.



One option is to spawn a worker process locally, return success, and process the task asynchronously. This works if your instance can keep up with all of the tasks sent to it. Under high load, however, an instance can become overwhelmed with background tasks and become unresponsive to higher-priority requests. If individual users can generate multiple tasks, the increase in load might not correspond to an increase in users, making it hard to scale out your web server tier effectively.

To avoid running long-running tasks locally, you can use the AWS SDK for your programming language to send them to an Amazon Simple Queue Service (Amazon SQS) queue and run the process that performs them on a separate set of instances. You then design these worker instances to take items from the queue only when they have the capacity to run them, preventing them from becoming overwhelmed.

Elastic Beanstalk worker environments simplify this process by managing the Amazon SQS queue and running a daemon process on each instance that reads from the queue for you. When the daemon pulls an item from the queue, it sends an HTTP POST request locally to http://localhost/ on port 80 with the contents of the queue message in the body. All that your application needs to do is perform the long-running task in response to the POST. You can configure the daemon to post to a different path, use a MIME type other than application/JSON, connect to an existing queue, or customize connections (maximum concurrent requests), timeouts, and retries.

Hence, the best solution to meet the requirements of this scenario is to use an Elastic Beanstalk worker environment to process the tasks asynchronously.

Spawning a worker process locally in the EC2 instances then processing the tasks asynchronously is incorrect. Although this is a valid solution, it is not scalable and hence, it’s not the best one. Under high load, an instance can become overwhelmed with background tasks and become unresponsive to higher priority requests. This makes it hard to scale out your web server tier effectively.

Using a multicontainer docker environment in Elastic Beanstalk to process the long-running tasks asynchronously is incorrect because this is primarily used to support multiple containers per Amazon EC2 instance with multicontainer Docker platform. This is not applicable when processing long-running tasks and it is not scalable since it’s not using an SQS queue.

Using an Amazon ECS Cluster with a Fargate launch type to process the tasks asynchronously is incorrect because Fargate just allows you to run your containerized applications without the need to provision and manage the backend infrastructure.


==============================================================================================================
	
A developer plans to use AWS Elastic Beanstalk to deploy a microservice application. The application will be implemented in a multi-container Docker environment.

How should the developer configure the container definitions in the environment?

(view)	1	0	1	00:01:06	
 Configure the container definitions in the Dockerrun.aws.json file.``````````````
 Configure the container definitions in the Amazon ECS Console when building the Docker environment.
 Configure the container definitions in the Dockerrun.aws.json.config and put it inside the .ebextensions folder.
 Use the eb config command to configure the container definitions.