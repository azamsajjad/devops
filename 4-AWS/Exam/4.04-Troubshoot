https://aws.amazon.com/faqs/

Well, for the Developer Associate Exam,
it's all about Serverless,
so make sure you read the FAQs for these services.
When it comes to the developer tools,
focus on CodeCommit, CodePipeline,
CodeDeploy, and CodeBuild.
For security, it's identity and access management,
Cognito, and KMS as well.
When it comes to automation and monitoring,
focus on CloudFormation, AWS SAM, CloudWatch, and X-Ray.
For Containers, make sure you read ECS and ECR.
And for messaging and streaming, its SQS and Kinesis.


https://aws.amazon.com/whitepapers


---------------------------------------------------------------------------
A developer wants to use CodeBuild to set up continuous integration for their project. They would like to ensure the project is integrated with the latest code and that the DevOps team is automatically notified of a failure in the build process by receiving an SMS message. Which of the following should the developer implement?

"Use CloudWatch Events and SES notifications to send a message to the DevOps team.

    SES is an email notification service; it cannot be used to send SMS messages."

Selected
Use the CodePipeline dashboard to view the CodeBuild events log.

Store the source code in EFS.

Use CloudWatch Events and an SNS topic to notify subscribers of build events.

    CodeBuild natively supports CloudWatch Events; SNS is a subscription-based notification service that integrates with CloudWatch.


"Store the source code in CodeCommit.

    CodeCommit is a supported source code repository for CodeBuild.
"


Add the name of the email group to the notifications section of the CodeBuild console.

    The CodeBuild console does not enable you to configure notifications in this way.


---------------------------------------------------------------------------
You are building a web application that uses API Gateway to expose a Lambda function to process requests from clients over the internet. While testing, the API Gateway frequently times out; however, when calling the Lambda function directly, it completes successfully every time.

Which of the following API Gateway metrics in Amazon CloudWatch should you check in order to troubleshoot the issue?

"Latency

    Latency relates to the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. This is useful because a latency issue could be causing the timeout."

Reference: API Gateway metrics

Count

CacheMissCount

    CacheMissCount relates to the number of requests served from the backend in a given period, when API caching is enabled. A cache miss should not cause API Gateway to time out, so this metric will not help you to understand why the API is timing out.

Reference: API Gateway metrics

Selected
"IntegrationLatency

    IntegrationLatency relates to the time between when API Gateway relays a request to the backend and when it receives a response from the backend. This is useful because a latency issue could be causing the timeout."

Reference: API Gateway metrics
---------------------------------------------------------------------------
You are designing a serverless online banking application that uses a Lambda function to process a credit check for new customers. The Lambda function makes an API call to an external third-party credit checking agency that performs the credit check and returns a response.

During performance testing, you discover that under peak load conditions, the third-party credit check API sometimes times out or returns an error, causing your function to fail. The support team has requested to receive notifications if the credit check API error rate exceeds 10% of the total number of transactions in any given hour. Which solution will meet these requirements?

Publish the results of the credit check to a DynamoDB table. Configure a Lambda function to query the table for failed invocations and notify an SNS topic when the error rate exceeds the specified rate.

Publish the failed credit check API calls to an SQS queue for further processing. Configure a CloudWatch alarm to send a message to the SQS queue when error rate exceeds the specified rate.

SQS is a message queueing service; it can not be used to notify the support team.

Selected
"Publish custom metrics to CloudWatch that record the failures of the credit check API calls. Configure a CloudWatch alarm to notify an SNS topic when the error rate exceeds the specified rate.

    Using CloudWatch, you can easily configure an alarm using a metric of your choice. When the alarm is triggered, CloudWatch can send a notification to an SNS topic to email the support team."

Reference: CloudWatch SNS Notifications

Publish the Lambda errors to CloudWatch Logs. Configure a Lambda function to query the CloudWatch Logs and notify an SNS topic when the error rate exceeds the specified rate.
---------------------------------------------------------------------------
You are storing user profile data for a mobile gaming application in a DynamoDB table. The product owner asks you to generate a list of all registered users that are located in the USA. As you retrieve the information from DynamoDB, you receive a ProvisionedThroughputExceededException error. What does the error ProvisionedThroughputExceededException mean in DynamoDB?

"You exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes.

    The ProvisionedThroughputExceededException means that you exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes."

Reference: Class ProvisionedThroughputExceededException

The DynamoDB table is unavailable.

The DynamoDB table has exceeded the allocated space.

The size of the query you tried to perform is too large. Find a way to split the query into a set of smaller queries.

It should not be necessary to split the query.
---------------------------------------------------------------------------
You are using CodeCommit to store the source code for your application. Whenever a team member creates or updates a pull request, you would like to trigger a Lambda function to save details of the pull request in a DynamoDB table. Which of the following should you implement in order to achieve this?

Use SNS to trigger the Lambda function whenever a pullRequestSourceBranchUpdated event is detected.

"Use EventBridge to trigger the Lambda function whenever a pullRequestCreated event or a pullRequestSourceBranchUpdated event is detected.

    EventBridge can be used to trigger a Lambda function based on CloudWatch metrics. The CloudWatch metrics to focus on are pullRequestCreated and pullRequestSourceBranchUpdated."

Reference: Monitoring CodeCommit Events

Use EventBridge to send a notification to SNS whenever a pullRequestCreated event or a pullRequestSourceBranchUpdated event is detected. Use SNS to trigger the Lambda function to save the data to DynamoDB.

It is not necessary to use an SNS topic to trigger the Lambda function. EventBridge can do this directly.

Selected
Use CloudWatch Logs Insights to trigger the Lambda function whenever a pullRequestCreated event or a pullRequestSourceBranchUpdated event is detected.---------------------------------------------------------------------------
A developer is working on a new JavaScript web application that allows users to post opinions to a shared forum and contribute to discussions about the latest innovations in cloud computing. Users have the ability to upvote their favorite posts, and at the end of each day, the top 250 posts are displayed in a leader board. The application makes a large batch request directly to DynamoDB using the BatchGetItem API call to report the most popular 250 posts. When a large request is made, the DynamoDB table frequently returns a partial result, accompanied by a value for UnprocessedKeys. Which of the following actions are ways that the developer can enable the application to receive all the remaining items when the BatchGetItem response includes a value for UnprocessedKeys?

"Retry the operation using an exponential backoff algorithm.

    If DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, AWS strongly recommends that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed."


"Update the application to use the AWS software development kit (AWS SDK) for JavaScript to make the API requests.

    AWS SDKs automatically implement retries using exponential backoff. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed."

Reference: Retry and Backoff with AWS SDKs

Retry the batch operation immediately.

Increase the provisioned read capacity of the DynamoDB table.

A single BatchGetItem operation can retrieve up to 100 items. BatchGetItem returns a partial result if the response size limit is exceeded. Increasing the read capacity will not help with this problem, because the application is making large batch requests of over 100 items.

Reference: BatchGetItem API Call

Selected
Increase the provisioned write capacity of the DynamoDB table.

BatchGetItem is a read operation, so increasing the write capacity of the table will not help.
.---------------------------------------------------------------------------
You are working on an application for an online training company that stores product data in DynamoDB. This week, the company is running a big promotion on a few courses, and this is bringing lots of new traffic to your website, causing an increased number of queries to the database. Database queries are now running much slower than usual, and the operations team is concerned that the DynamoDB table is being throttled. Which of the following approaches would you recommend to improve read performance?

Redesign your table to use a more distinct partition key to enable the I/O load to be more evenly distributed across partitions.

Add a read replica and point the DynamoDB API calls at the read replica.

Configure the application to use scans rather than queries and run multiple scans in parallel.

"Configure a DAX cluster and point the DynamoDB API calls at the DAX cluster.

    Using DAX is the recommended approach to reducing response times for read-intensive applications, applications that read a few items frequently, and applications that perform repeated reads against a large set of data."
---------------------------------------------------------------------------
Your application uses Kinesis to collect customer data from various sources, including web forms, mobile apps, and IoT devices. This data is analyzed in real time in order to gain insights and improve customer experience. Following a recent Black Friday event, your website experienced unprecedented traffic, and sales have doubled over the last quarter. This increase in traffic caused some issues, and your Kinesis stream is frequently throwing a ProvisionedThroughputExceededException error. What should you do to fix this problem?

Provision a second Kinesis stream to handle the additional load. Use a Lambda function to merge the processed data from the two streams.

"Reduce the frequency or size of your requests.

    ProvisionedThroughputExceededException means that the request rate for the stream is too high or the requested data is too large for the available throughput. Reducing the frequency or size of requests will reduce the throughput that is being used."

Reference: ProvisionedThroughputExceededException

Selected
Increase the number of consumers.

Retry the operation immediately.

"Reshard your stream.

    Resharding your stream to increase the number of shards in the stream allows you to adjust the number of shards in your stream to adapt to changes in the rate of data flow through the stream."
---------------------------------------------------------------------------




2
---------------------------------------------------------------------------





---------------------------------------------------------------------------
You are troubleshooting a major incident that resulted in data loss in your application. Your manager asks if you can provide a time-ordered sequence of any modifications that happened to the items in your DynamoDB table over the past 24 hours so that you can work out what happened. Provided any pre-configuration that was completed, which service could you use to most efficiently provide this?

Kinesis Data Streams

CloudTrail

CloudTrail could be used to help identify the API calls made to DynamoDB; however, this is not the most efficient way to gather this data. CloudTrail is not designed to enable you to provide a time-ordered sequence of any modifications that happened to the items in your DynamoDB table.

Selected
"DynamoDB Streams

DynamoDB Streams captures a time-ordered sequence of item-level modifications in a DynamoDB table and durably stores the information for up to 24 hours."
---------------------------------------------------------------------------
You are trying to diagnose a performance problem with your serverless application, which uses Lambda, API Gateway, S3, and DynamoDB. Your DynamoDB table is performing well, and you suspect that your Lambda function is taking too long to execute. Which of the following could you use to investigate the source of the issue?

// Lambda invocations sum metric in CloudWatch

// Lambda invocations sum measures the number of times a function is invoked in response to an event or invocation API call.

// Selected
// API Gateway latency metric in CloudWatch

// API Gateway latency is the time between when API Gateway receives a request from a client and when it returns a response to the client.

Selected
"AWS X-Ray

AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway integration latency is the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda invocations sum measures the number of times a function is invoked in response to an event or invocation API call."

Reference:

"API Gateway CloudWatch Metrics
Lambda CloudWatch Metrics
X-Ray FAQs
Using Latency Histograms in the AWS X-Ray Console
API Gateway integration latency metric in CloudWatch

AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway integration latency is the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda invocations sum measures the number of times a function is invoked in response to an event or invocation API call."
---------------------------------------------------------------------------
You have a distributed application that is made up of a number of different Lambda functions as well as API Gateway endpoints and DynamoDB tables. You have noticed that the application is running unusually slow today. Which of the following tools would be the best choice to help identify what is going on?

VPC Flow Logs

VPC Flow Logs cannot be used to identify performance issues in distributed serverless applications.

Selected
CloudTrail

CloudWatch

"X-Ray

AWS X-Ray helps developers analyze and debug production, distributed applications, such as those built using a microservice architecture. With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors."
---------------------------------------------------------------------------

Your API Gateway endpoint is experiencing server errors indicated by a 5xx HTTP response code. How can you increase the reliability of the application while reducing operational costs?

"Configure your application to use retry logic with exponential backoff.

Server errors are indicated by a 5xx HTTP response code and need to be resolved by Amazon. You can resubmit or retry the request until it succeeds. Numerous components on a network, such as DNS servers, switches, load balancers, and others can generate errors anywhere in the life of a given request. The usual technique for dealing with these error responses in a networked environment is to implement retries in the client application. Each AWS SDK implements automatic retry logic with an exponential backoff algorithm for better flow control. If you are not using an AWS SDK, you should retry original requests that receive server (i.e., 5xx) or throttling errors. However, client errors (i.e., 4xx) indicate that you need to revise the request to correct the problem before trying again."

Reference: Error Retries and Exponential Backoff in AWS.

Distribute the load by adding an Elastic Load Balancer in front of the API Gateway.

Increase capacity by scaling the backend of your API.

This indicates an internal problem with your API. Fix the issue in your API and try the request again.

This does not indicate an internal problem with your API.

---------------------------------------------------------------------------

You are supporting a legacy application that runs on a virtual machine running RedHat Linux in your own data center. Your CTO asks you to ensure that all RedHat instances in the legacy data center are monitored using CloudWatch. You also need to ensure that the support team is notified by email if an error message appears in the application log file. Which of the following do you recommend?

Configure a Lambda function that periodically connects to the application servers and monitors the application log file. Use a CloudWatch alarm to trigger an SNS notification if an error appears in the application log file.

"Install the CloudWatch agent on the Linux servers. Configure the agent to monitor the application log file. Use a CloudWatch alarm to trigger an SNS notification if an error appears in the application log file."

You will need to install the CloudWatch agent on each of the on-premises servers. You can configure the CloudWatch agent to collect the log data that you want to monitor, and send it to CloudWatch Logs. CloudWatch alarms can be used to monitor the log data and alert the team using SNS when something goes wrong.

Install the CloudWatch agent on the Linux servers. Configure the agent to monitor the operating system messages file. Use a CloudWatch alarm to trigger an SNS notification if an error appears in the messages file.

CloudWatch should trigger the alarm if an error message appears in the application log file, not the operating system messages file.

Selected
Update your application code to send application log data to CloudWatch logs. Use a CloudWatch alarm to trigger an SNS notification if an error appears in the application log file.
---------------------------------------------------------------------------





3
---------------------------------------------------------------------------






---------------------------------------------------------------------------
A developer wants to track the average time it takes to complete customer transactions for an application running on a group of EC2 instances, including the ability to view and track statistics, like how long it takes to complete an average customer request and the maximum request latency, across the all instances. The support team would like to receive an immediate notification if the average transaction completion time exceeds three seconds for one minute or longer. Which of the following will meet these requirements?

/Configure the application to record transaction completion times to an application log file/. 'Install and configure the CloudWatch agent on the EC2 instances, and send the application log to CloudWatch Logs. Use a metric filter based on transaction completion time, and create a CloudWatch dashboard based on the metric to view the latest statistics. Configure a CloudWatch alarm to send an SNS notification to the support team if the average transaction completion time exceeds three seconds for one minute or longer.

    The CloudWatch agent is used to send logs to CloudWatch. You can create a metric filter to filter the information contained in the logs.'

Configure the application to record transaction completion times to the operating system log file. Install and configure the Amazon CloudWatch agent on the EC2 instances and send the operating system log to CloudWatch Logs. Use a metric filter based on transaction completion time, and create a CloudWatch dashboard based on the metric to view the latest statistics. Configure a CloudWatch alarm to send an SQS notification to the support team if the average transaction completion time exceeds three seconds for one minute or longer.

Install and configure the Amazon CloudWatch agent on the EC2 instances to send operating system metric data to CloudWatch. Use a metric filter based on transaction completion time, and create a CloudWatch dashboard based on the metric to view the latest statistics. Configure a CloudWatch alarm to send an SNS notification to the support team if the average transaction completion time exceeds three seconds for one minute or longer.

The transaction completion is related to the application, therefore data relating to transaction completion times would not be included in the operating system metric data provided by the CloudWatch agent.

Selected
Configure a Lambda function to record transaction completion times, and add them to a log file stored in S3. Use Athena to query the S3 data based on transaction completion time, and create a CloudWatch dashboard based on the completion times to view the latest statistics. Configure a CloudWatch alarm to send an SNS notification to the support team if the average transaction completion time exceeds three seconds for one minute or longer.
---------------------------------------------------------------------------
Your API Gateway endpoint is experiencing server errors indicated by a 5xx HTTP response code. How can you increase the reliability of the application while reducing operational costs?

This indicates an internal problem with your API. Fix the issue in your API and try the request again.

This does not indicate an internal problem with your API.

Reference: Error Retries and Exponential Backoff in AWS.

Selected
'Configure your application to use retry logic with exponential backoff.

        Server errors are indicated by a 5xx HTTP response code and need to be resolved by Amazon. You can resubmit or retry the request until it succeeds. Numerous components on a network, such as DNS servers, switches, load balancers, and others can generate errors anywhere in the life of a given request. The usual technique for dealing with these error responses in a networked environment is to implement retries in the client application. Each AWS SDK implements automatic retry logic with an exponential backoff algorithm for better flow control. If you are not using an AWS SDK, you should retry original requests that receive server (i.e., 5xx) or throttling errors. However, client errors (i.e., 4xx) indicate that you need to revise the request to correct the problem before trying again.'

Reference: Error Retries and Exponential Backoff in AWS.

Increase capacity by scaling the backend of your API.

Distribute the load by adding an Elastic Load Balancer in front of the API Gateway.
---------------------------------------------------------------------------

You are testing a new serverless application that uses Lambda, S3, DynamoDB and API Gateway. You are suddenly seeing a large number of 4XX HTTP response codes coming from API Gateway. What could be the problem, and what should you do about this?

This indicates an internal problem with your API. Fix the issue in your API and try the request again.

This indicates an internal problem with your API Gateway instance. Provision a new API Gateway instance and try the request again.

'This is a client error. You should fix the issue in your application and retry the request.

Client errors: Client errors are indicated by a 4xx HTTP response code. Client errors indicate that Amazon API Gateway found a problem with the client request, such as an authentication failure or missing required parameters. Fix the issue in the client application before submitting the request again. Server errors: Server errors are indicated by a 5xx HTTP response code, and need to be resolved by Amazon. You can resubmit or retry the request until it succeeds.'

Reference: Handling Errors in Amazon API Gateway Reference: API Gateway Response Codes

Selected
This is an AWS error. You should wait for AWS to fix the issue and retry the request.
---------------------------------------------------------------------------

Your application interacts with an RDS database for storing customer data relating to your online gaming application. You have noticed that during times of intensive read activity, the database and whole application slows down, causing customers to complain. Which of the following could you implement to improve performance?

'Add a read replica to improve performance for read queries. Point the application servers to the read replica.

A read replica will improve performance for read-only queries to an RDS database.'

Selected
Move the dataset to DynamoDB for faster response times.

Add a DynamoDB Accelerator (DAX) cluster to improve performance for read queries. Point the application servers to the DAX cluster.

Add a MemoryDB for Redis instance to improve performance for read queries. Point the application servers to MemoryDB for Redis.

'Add an ElastiCache cluster to improve performance for read queries. Point the application servers to the ElastiCache cluster.

ElastiCache is an in-memory caching service that can be used to cache the results of I/O-intensive database queries, which helps improve performance for database reads.'

---------------------------------------------------------------------------
You are running an online fitness tracker application on a number of EC2 instances behind an Elastic Load Balancer. You have noticed some anomalies with the way the application is performing lately and would like to collect the application logs from all of your application servers into one central location. Which of the following will you need to do for each instance?

'Ensure the CloudWatch agent is installed and running on your EC2 instance.'

You need the agent installed and running on your EC2 instance.

Reference: Collect Metrics and Logs from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent.

Selected
Ensure the CloudWatch agent has permission to write the application log files on your EC2 instance.

Ensure the instance role associated with your EC2 instance has permission to write the application logs to S3.

Ensure the instance role associated with your EC2 instance has read permission for CloudWatch.

'Ensure the instance role associated with your EC2 instance has permission to write the application logs to CloudWatch.

You need to configure permission for the EC2 instance role to write your application logs to CloudWatch i.e., permission' to /CreateLogGroup/
                /CreateLogStream/
                    /PutLogEvents/ 
                        /DescribeLogStreams/
---------------------------------------------------------------------------
---------------------------------------------------------------------------





4
---------------------------------------------------------------------------






---------------------------------------------------------------------------

Your application is running on EC2 and sending metrics to CloudWatch. You would like to create a single custom view to display the data relating to the production instances of your application so that you can view application health at a glance. How can you do this using CloudWatch?

Create a namespace to display the metrics that you would like to view. Use a dimension to filter the results to only show the EC2 instances that are in your production environment.

Create a dashboard to display the metrics that you would like to view. Use a namespace to filter the results to only show the EC2 instances that are in your production environment.

A namespace is a container for CloudWatch metrics (e.g., EC2 uses the AWS/EC2 namespace). A namespace cannot be used to filter the results to only show the EC2 instances that are in your production environment.

Selected
'Create a dashboard to display the metrics that you would like to view. Use a dimension to filter the results to only show the EC2 instances that are in your production environment.

    A dashboard is like a custom homepage that you create in CloudWatch (e.g., you can display important metrics for all of your production systems in one place). A dimension is like a filter (e.g., you can use the InstanceId dimension to search for metrics related to a specific EC2 instance).'

Create a namespace to display the metrics that you would like to view. Use a filter expression to filter the results to only show the EC2 instances that are in your production environment.

---------------------------------------------------------------------------
You have developed a CloudFormation stack in the AWS Management Console. You have a few CloudFormation stacks saved in the Region in which you are operating in. When you launch your stack that contains many EC2 resources, you receive the error Status=start_failed. How would you troubleshoot this issue?

Use the Support Center in the AWS Management Console to request an increase in the number of CloudFormation stacks.

The default limit for CloudFormation stacks is 200, and the question explicitly states that there are only a very small number of existing stacks.

Reference: Troubleshooting AWS CloudFormation

Selected
'Verify that you didnt reach a resource limit, then use the Support Center in the AWS Management Console to request an increase in the number of EC2 instances.

    You should verify that you didnt reach a resource limit. The default number of EC2 instances that you can launch is 20. If you try to create more Amazon EC2 instances than your account limit, the instance creation fails, and you receive the error Status=start_failed. Also, during an update, if a resource is replaced, AWS CloudFormation creates a new resource before it deletes the old one. This replacement might put your account over the resource limit, which would cause your update to fail. You can delete excess resources or request a limit increase.
'
Reference: Troubleshooting AWS CloudFormation

Wait a few minutes before saving the template and retry the process.

Save the template via the AWS CLI.
---------------------------------------------------------------------------
A high-traffic news website is experiencing performance issues during peak times. Investigation reveals that the top news stories are impacting the database performance. Top news stories must be updated every 15 minutes. What would be an optimal and non-intrusive solution to fix this performance problem?

Upgrade the database instance to a more powerful instance type.

Create read replicas of the database. Distribute the read traffic to the read replicas.

'Create a CloudFront distribution. Configure TTL to 900 seconds.

    The optimal solution is to create a CloudFront distribution and configure the TTL to 900 seconds. CloudFront can cache the top news stories. It is a highly available and highly scalable service, ensuring that any sudden increase in web traffic can be accommodated. Setting the TTL to 900 seconds ensures that the news stories are refreshed in the CloudFront distribution according to the specified requirements.'

Reference:

What Is Amazon CloudFront?
Managing How Long Content Stays in an Edge Cache (Expiration)
Implement ElastiCache in front of the database.

Implementing ElastiCache is not an optimal solution, as it would require application re-engineering to take advantage of the service.
---------------------------------------------------------------------------
An application developer finds that performing a scan operation on a large DynamoDB table is taking a long time to execute. What can be used to improve the performance and decrease the execution time of the scan operation?

Use of pagination

Pagination can be used to divide the result set into multiple pages, but it does not increase the performance of the scan operation.

Selected
Use of a filter expression

'Use of parallel scans

    Parallel scans can be used by multiple worker threads in an application to perform a scan of a DynamoDB table much faster.'

Reference: Parallel Scan

Use of projection expression
---------------------------------------------------------------------------
You have developed an application that automatically tracks home deliveries for online orders from a number of different websites. You would like your application to send metrics to CloudWatch any time a critical error occurs, and you want CloudWatch to notify you if more than two critical errors occur within a time period of 15 minutes. Which of the following CloudWatch actions can you use to configure this?

Use InputMetricData to publish metric data relating to critical errors to CloudWatch. Use CreateMetricAlarm to create an alarm and notify you if the threshold is reached.

There are no CloudWatch actions named InputMetricData or CreateMetricAlarm.

Selected
Use GetMetricData to fetch metrics relating to critical errors from the application. Use PutMetricAlarm to create an alarm and notify you if the threshold is reached.

Use PutMetricAlarm to publish metric data relating to critical errors and alert you if the threshold is reached.

'Use PutMetricData to publish metric data relating to critical errors to CloudWatch. Use PutMetricAlarm to create an alarm and notify you if the threshold is reached.

    PutMetricData is used to publish metric data points to CloudWatch. PutMetricAlarm can be used to create an alarm and associate it with a metric and threshold.'
---------------------------------------------------------------------------
You are building an application that generates a new online word puzzle every day and allows players to share their scores on social media. You would like to configure your application to send custom metric data to CloudWatch. Which of the following CloudWatch actions could you use to achieve this?

PutMetricStream

ImportMetricData

'PutMetricData

PutMetricData is used to publish metric data points to CloudWatch.'

Selected
PutMetricAlarm
---------------------------------------------------------------------------
Your application reads data from an SQS queue. The reads are then forwarded to a Lambda function for processing critical customer information, including purchasing and inventory data. It is critical that no data is ever lost. How could you ensure that no data is lost in the event of a malfunction with the Lambda processing?

Requeue failed messages with a VisibilityTimeout of 30 seconds.

Requeue the failed message with DelaySeconds set to 3.

Create a FIFO queue and set DelaySeconds to 3.

'Create a dead-letter queue and set the Maximum Receives to 3.

    A dead-letter queue would allow you to prevent data loss. After a message is taken from the queue and returned for the maximum number of retries, it is automatically sent to a dead letter queue, if one has been configured. It stays there until you retrieve it for forensic purposes. You can configure the number of times that a message can be received before being sent to a dead-letter queue. This is the Maximum Receives parameter, which can be any value between 1 and 1,000.'