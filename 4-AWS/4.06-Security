PREVENT

DETECT

RESPOND

REMEDIATE

"Confidentiality, integrity, and availability"

Security is the practice of protecting your intellectual property from unauthorized access, use, or modification. The confidentiality, integrity, and availability (CIA) triad model highlights the important aspects of information security within an organization. AWS provides several services that you can use to address the needs that this model describes. Select each of the following cards for more information on the CIA triad.

\
Confidentiality refers to limiting information access and disclosure to authorized users (the right people) and preventing access by unauthorized people. 

\
Integrity involves maintaining the consistency, accuracy, and trustworthiness of data over its entire life cycle. From a more restrictive view, the integrity of an information system includes only preservation without corruption of whatever was transmitted or entered into the system.

\
Availability refers to the readiness of information resources. An information system that is not available when you need it is almost as useless as not having an information system. 


AWS shared responsibility model

AWS is responsible for protecting the global infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure comprises the hardware, software, networking, and facilities that run AWS services.

As an AWS customer, you are responsible for securing your data, operating systems, networks, platforms, and other resources that you create in the AWS Cloud. You are responsible for protecting the confidentiality, integrity, and availability of your data and for meeting any specific business or compliance requirements for your workloads.

Safeguarding data is a critical part of building and operating information systems. AWS provides services and features that give you several options to protect your data at rest and in transit. These options include fine-grained access controls to objects, creating and controlling the encryption keys used to encrypt your data, selecting appropriate encryption methods, validating integrity, and appropriately retaining data. Creating mechanisms to protect data in transit, such as using virtual private network (VPN) and Transport Layer Security (TLS) connections, is also a security best practice.

The AWS Well-Architected Framework

The AWS Well-Architected Framework helps you understand the pros and cons of decisions you make while building systems on AWS. By using the AWS Well-Architected Framework, you will learn architectural best practices for designing and operating reliable, secure, efficient, and cost-effective systems in the cloud. It provides a way for you to consistently measure your architectures against best practices and identify areas for improvement. AWS believes that having well-architected systems greatly increases the likelihood of business success. 

The framework is based on six pillars. Select each of the following numbered markers for more information: 

Operational Excellence
Security
Reliability
Performance Efficiency
Cost Optimization
Sustainability

The security pillar

The security pillar signifies the ability to protect information, systems, and assets while delivering business value through risk assessments and mitigation strategies. The security pillar is made up of five different areas for security in the cloud. All AWS security services can be categorized by these five areas. Select each of the following markers for more information on the different security pillar areas.
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
IAM-DETECTIVE CONTROLS-INFRA PROTECTION-DATA PROTECTION-INCIDENT RESPONSE
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
1-1-1-1-1-1-1-1-1-1-1-1--1-1-1-1-1-1-1----------------------IAM:
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-

Authentication - Who? e.g. using passwords to authenticate
Authorization - What?
Sometimes in Authorization, the most important question is not what can users do, but what can they NOT do.

Amazon Cognito
+

AWS Directory Service
+

AWS Identity and Access Management (IAM)
+
AWS Directory Service is a managed service offering that provides directories that contain information about your organization, including users, groups, computers, and other resources. As a managed offering, AWS Directory Service is designed to reduce management tasks, thereby allowing you to focus more of your time and resources on your business. 

AWS IAM Identity Center (formerly known as AWS Single Sign-On)
–
AWS IAM Identity Center is a cloud SSO service that allows for the central management of SSO access to multiple AWS accounts and business applications. It enables users to sign in to a user portal with their existing corporate credentials and access all of their assigned accounts and applications from one place. IAM Identity Center includes built-in Security Assertion Markup Language (SAML) integrations to many business applications. IAM Identity Center may be integrated with Microsoft Active Directory, which means your employees can sign in to your user portal using their corporate Active Directory credentials. 
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2--------------DETECTIVE CONTROLS.
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
AWS services for detective controls

AWS provides a suite of services that will monitor and combat threats through unified security and compliance, managed threat detection, application security analysis, and the ability to investigate potential security issues. 


AWS Security Hub
–
AWS Security Hub provides you with a comprehensive view of your security state within AWS and your compliance with security standards and best practices. Security Hub centralizes and prioritizes security findings from across AWS accounts, services, and supported third-party partners to help you analyze your security trends and identify the highest priority security issues. provides a dashboard and include findings from GaurdDuty, Macie, Detective, Compliance Checks and partners
@ It continuously aggregates and prioritize findings
@ Conduct automated compliance scans and checks
@ AWS Security Hub provides integrated dashboards that bring together your security findings across accounts to show you the current security and compliance status. You can easily spot trends, identify potential issues, and take the necessary next steps.
@ Can take actions - AWS Security Hub supports integration with Amazon CloudWatch Events. This integration lets you automate the remediation of specific findings by defining custom actions to take when a finding is received. 
                                                    -->Yellow -> Lambda 1
Security Hub -> Findings -> Cloudwatch Events Rule _|
                                                    |-->Red -> SNS notify security team


Amazon GuardDuty
+
Amazon GuardDuty offers threat detection that enables you to continuously monitor and protect your AWS accounts and workloads. GuardDuty analyzes continuous streams of metadata generated from your account and network activity found in CloudTrail events, Amazon Virtual Private Cloud (Amazon VPC) flow logs, and Domain Name System (DNS) logs. It also uses integrated threat intelligence such as known malicious IP addresses, anomaly detection, and machine learning to identify threats more accurately. 
-------------
GuardDuty's threat intelligence coupled with machine learning and behavior models help you detect activity such as crypto-currency mining, credential compromise behavior, or API calls from known malicious IPs.
-------------
Through the multi-account feature, all member accounts findings can be aggregated with a GuardDuty administrator account. This enables the security team to manage all GuardDuty findings from across the organization in one single account.
-------------
Your security team and administrators can use AWS Identity and Access Management (IAM) Access Analyzer to identify resources that can be accessed from outside an AWS account.
-------------
GuardDuty comes integrated with up-to-date threat intelligence feeds from AWS, CrowdStrike, and Proofpoint.
-------------'



Amazon Inspector
+
Amazon Inspector is an automated security assessment service that helps you test the network accessibility of your Amazon Elastic Compute Cloud (Amazon EC2) instances and the security state of your applications running on the instances. 




Amazon Detective
+
Amazon Detective makes it easy to analyze, investigate, and quickly identify the root cause of potential security issues or suspicious activities. Detective automatically collects log data from your AWS resources and uses machine learning, statistical analysis, and graph theory to build a linked set of data that enables you to easily conduct faster and more efficient security investigations.




Amazon Macie
+
Amazon Macie is a security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. Macie recognizes sensitive data such as personally identifiable information (PII) or intellectual property and provides you with dashboards and alerts that give visibility into how this data is being accessed or moved. The fully managed service continuously monitors data access activity for anomalies and generates detailed alerts when it detects risk of unauthorized access or inadvertent data leaks. Macie is available to protect data stored in Amazon S3.
"@ bullet
Macie can identify data with high business value, including programming languages, to detect source code, logging formats, database backup formats, credentials, and API key formats.
@ bullet
The user behavior analytics engine of Macie helps identify risky or suspicious activity with AWS service API calls and access to high-value content.
@ bullet
Macie allows you to integrate with SIEM services and managed security service provider (MSSP) solutions. "


Here is an example of a corporation using AWS Direct Connect to create a hybrid connection to AWS. All production data is being sent to AWS for storage, archiving due to compliance requirements, and analysis via Amazon Athena. With the addition of Macie, data is now being monitored and classified for the following:

Anonymous access via the analysis of AWS CloudTrail logs and events
PII artifacts inside a public Amazon S3 bucket
Amazon S3 buckets and objects with certain keywords
Amazon S3 objects containing certain type of data
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
3-3-3-3-3-3-3-3-3-3-3-3--3-3-3-3-33-----INFRASTRUCTURE PROTECTION.
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-

AWS Shield
+
AWS Shield is a managed service that provides protection against distributed denial of service (DDoS) attacks for applications running on AWS. AWS Shield Standard is automatically enabled to all AWS customers at no additional cost.
AWS Shield is a managed DDoS protection service that safeguards applications running on AWS. A DDoS attack is an attack in which multiple compromised systems attempt to flood a target, such as a network or web application, with traffic. A DDoS attack can prevent legitimate users from accessing a service and can cause the system to crash due to the overwhelming traffic volume.

AWS provides two levels of protection against DDoS attacks: 

AWS Shield Standard (enabled by default and comes with no additional cost)
Always-on detection	           ✔  ✔
Automatic inline mitigation	    ✔	✔
Layer 3 and 4 protection        ✔  ✔
(AWS Shield Advanced)
Expanded DDoS attack protection	✔
24/7 DDoS response team	       ✔
Cost protection for DDoS spikes	✔
Access to real-time reports        ✔
AWS Shield integrates with Amazon Route 53, Amazon CloudFront, and Elastic Load Balancing to protect your applications from DDoS attacks.
bullet
AWS Shield Advanced provides real-time metrics and reports for extensive visibility into attacks on your AWS resources.

AWS WAF
–
AWS WAF is a web application firewall that helps protect web applications from attacks by allowing you to configure rules that allow, block, or monitor (count) web requests based on conditions that you define. These conditions include IP addresses, HTTP headers, HTTP body, uniform resource identifier (URI) strings, structured query language (SQL) injection, and cross-site scripting.  

If you have request sampling enabled, you
can view a sample of the requests that AWS
WAF has inspected and either allowed or
blocked. For each sampled request, you can
view detailed data about the request, such as
the originating IP address and the headers
included in the request. You can also view
the rules that matched the request, and the
rule action settings.

Intelligent Application Protection
Concept
The core rule set (CRS) rule group contains
rules that are generally applicable to web
applications. This provides protection against
exploitation of a wide range of
vulnerabilities, including some of the high
risk and commonly occurring vulnerabilities
described in OWASP publications, such as
the OWASP Top 10. The SQL database rule
group contains rules to block request
patterns associated with exploitation of SQL
databases, such as SQL injection attacks. This
can help prevent remote injection of
unauthorized queries.


Which of the following are benefits of integrating AWS Firewall Manager withAWS Organizations ? (Select TWO)

``Firewall Manager monitors for new resources created to ensure they comply with a mandatory set of security policies.
You can configure Amazon RDS database engines and Database parameters.
``You can enable AWS WAF rules, AWS Shield Advanced protections, Amazon VPC security groups and AWS Network Firewalls.
You can centrally manage Amazon S3 Lifecycle configuration on a bucket.

AWS Firewall Manager
+
AWS Firewall Manager is a security management tool that makes it easier for you to configure your AWS WAF rules across your accounts. With Firewall Manager, security administrators of large organizations can write company-wide rules from one place, enforce them across applications protected by AWS WAF, and get the central visibility of attacks against their Application Load Balancers and Amazon CloudFront infrastructure. 

-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
4-4-4-4-4-4-4-4-4-44-4-4-4-4-4-4-4-4------DATA PROTECTION.
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
AWS Key Management Service (KMS)
+

AWS CloudHSM
+

AWS Certificate Manager (ACM)
+

AWS Secrets Manager
+
PARAMETER STORE
SECRETS MANAGER 
KMS 
ACM 
Route 53
-----------------------------------------------------------------
AWS SYSTEMS MANAGER - PARAMETER STORE 
    safe place to store licence keys, passwords, database connection strings,  in plain text or encrypted
    you can reference your parameters using parameter name e.g. in a script
    its integrated to be used with ec2, cloudformation, lambda, codebuild, codepipeline, codedeploy

AWS SECRETS MANAGER 
    secrets are encrypted using AWS KMS key
    CMK customer master key holds key material to encrypt data. CMKs can encrypt upto 4kb of data
    Secret Rotation is done through lambda function


AWS SYSTEMS MANAGER - PARAMETER STORE 
PARAMETER POLICIES
helpful in updating or deleting passwords 
you can assign multiple policies to a parameter 
3 Policies 
-Expiration
       deletes the parameter after specified date and time
{       
       "Type":"Expiration",
       "Version":"1.0",
       "Attributes":{
              "Timestamp":"2023-12-21T21:34:22.000Z"
       }
}
-ExpirationNotification
       notifies you about upcoming expiration via CloudWatch Events
{       
       "Type":"ExpirationNotification",
       "Version":"1.0",
       "Attributes":{
              "Before":"15",
              "Unit":"Days"
       }
}
-NoChangeNotification - 
       policy triggers an event in CloudWatch if a parameter has not been modifiedfor a specified period of time
{       
       "Type":"NoChangeNotification",
       "Version":"1.0",
       "Attributes":{
              "After":"15",
              "Unit":"Days"
       }
}
CLI: (put parameter)
aws ssm put-parameter --name "/planet/popultion" --value 4.9B --type String
aws ssm put-parameter --name "/planet/gravity" --value 1.4G --type String
aws ssm put-parameter --name "/planet/class" --value M --type String

aws ssm get-parameters-by-path --path /planets


AWS Systems Manager Parameter Store 

AWS Systems Manager has an additional capability called Parameter Store that provides you with secure, hierarchical storage for configuration data management and secrets management. You can store data such as passwords, database strings, Amazon Machine Image (AMI) IDs, and license codes as parameter values.  In addition, Parameter Store includes the following:


bullet
Free, fully managed, centralized storage system for configuration data and secret management.


bullet
Data can be stored in plain text or also encrypted with AWS Key Management System (AWS KMS).


bullet
Parameter Store tracks all parameter changes through versioning, so if you need to roll back your deployment, you can also choose to use an earlier version of your configuration data.

Parameter Store: Hierarchical key storage

Parameter Store provides hierarchical key-value storage. You can create a hierarchy for each of your environments (dev, stage, and prod), and then have the API keys that you need for each environment.


This diagram shows that you can access an API key in a development environment without exposing the staging or production API keys.

Depending on the environment you’re in, you can pull the correct key without exposing your other keys.


===============================================
Pulling configuration data from Parameter Store might increase latency when you call your Lambda function. How can you reduce this latency, while maintaining security best practices?


Pull configuration data from Parameter Store and store it in a global variable. Use function code to check if you need to pull or update the parameter.
-----------------------------------------------------------------
AWS SECRETS MANAGER 
secrets are encrypted using AWS KMS key
    CMK customer master key holds key material to encrypt data. CMKs can encrypt upto 4kb of data
    Secret Rotation is done through lambda function

RDS,Redshift,DocumentDB,otherDB,key/value
e.g. for postgreSQL
Server address:
Database name:
Port: 

Enforced Encrypton with kms 
$0.40 per secret per month 
$0.05 per 10k API calls 
good value why: automatic rotation
       rotation interval
       30 days to 1 year
workaround: use lambda with parameter store to rotate secrets - free 

CloudTrail can monitor credentials access in case you need to audit secrets

CLI:
$ aws secretsmanager describe-secret --secret-id enterprize/shipdatabase
$ aws secretsmanager get-secret-value --secret-id enterprize/shipdatabase --version-stage AWSCURRENT
XXXXXXXXXXXX
Secrets Manager helps you meet your security and compliance requirements by enabling you to rotate secrets safely without the need for code deployments. 
XXXXXXXXXXXX
With Secrets Manager, you can manage access to secrets using fine-grained AWS Identity and Access Management (IAM) policies and resource-based policies.
XXXXXXXXXXXXXX
Secrets Manager offers built-in integration for Amazon Relational Database Service (Amazon RDS), Amazon Redshift, and Amazon DocumentDB (with MongoDB compatibility) and automatically rotates these database credentials on your behalf.
XXXXXXXXXXXXXX
Using Secrets Manager, you can secure secrets by encrypting them with encryption keys that you manage using AWS KMS.
XXXXXXXXXXXXXXX
Secrets Manager also integrates with AWS logging and monitoring services for centralized auditing.
XXXXXXXXXXXXXXXX
With Secrets Manager, you pay for the number of secrets managed in Secrets Manager and the number of Secrets Manager API calls made.



-----------------------------------------------------------------
KMS is upto FIPS 140-2 Level 2 Complient
------------------------------KMS - Key Management Service 
-----------------------------------------------------------------
-----------------------------------------------------------------
STEP1:
Data delivery
With server-side encryption (SSE), data is
delivered to AWS via HTTPS. The service then
encrypts the data after it receives the API call.
In this case, the service is Amazon Simple
Storage Service (Amazon S3). SSE is transparent
to the end user

STEP2:
Data key
AWS KMS then generates a data key, and
Amazon S3 uses this data key to encrypt each
object that it receives. Each object will have it
own unique data key.

STEP3:
Customer master key
The data key is then encrypted under a
customer master key (CMK) that either AWS or
the customer can manage and rotate. AWS KMS
tracks which master key was used to encrypt
the data key.

STEP4:
Key storage
The encrypted data key is then stored with the
encrypted data so that the service knows where
to find the key to decrypt the data at a later
time.


Types of CMKs

"AWS KMS can use two types of CMKs when encrypting data keys: AWS managed and customer managed. The following table summarizes the key differences and similarities between AWS managed CMKs and customer managed CMKs."
-----------------------
With AWS KMS, you control access to your encrypted data by defining the permissions to use the keys while AWS KMS enforces your permissions and handles -the durability and physical security of your keys. 
bullet--------------------------------
"AWS KMS presents a single control point to manage keys and define policies consistently across integrated AWS services and your own applications-."
bullet------------------------
AWS KMS is integrated with the AWS Encryption SDK to enable you to use AWS KMS protected data encryption keys to encrypt locally within your applications. 
bullet---------------------
"The security and quality controls in AWS KMS have been certified under multiple compliance schemes to simplify your own compliance obligations.
bullet"--------------------
AWS KMS is integrated with AWS services to simplify using your keys to encrypt data across your AWS workloads. 
--------------------------

use KMS whenver you are dealing with sensitive data
S3, RDS, DynamoDB, Lambda, EBS, EFS, CloudTrail, DeveloperTools
CMK? Customer Master Key = encrypt/decrypt data upto 4kb 
Generate / Encrypt / Decrypt the Data Key 
using that Data Key to encrypt/d your data is EnvelopeEncryption

aws kms create-key 
aws kms encrypt --key-id YOURKEYIDHERE --plaintext fileb://secret.txt --output text --query CiphertextBlob | base64 --decode > encryptedsecret.txt

aws kms decrypt --ciphertext-blob fileb://encryptedsecret.txt --output text --query Plaintext | base64 --decode > decryptedsecret.txt

aws kms re-encrypt --destination-key-id YOURKEYIDHERE --ciphertext-blob fileb://encryptedsecret.txt | base64 > newencryption.txt 
(use re-encrypt command to encrypt a file with a different CMK)
(manual rotation)

aws kms enable-key-rotation --key-id YOURKEYIDHERE
(auto key rotation) once per 365 days

aws kms get-key-rotation-status --key-id YOURKEYIDHERE

aws kms generate-data-key --key-id YOURKEYIDHERE --key-spec AES_256
(use it if data is larger than 4kb)
this command creates a data key a.k.a Envelope Key 
CMK encrypts the-> Data/Envelope Key-> is then used to Encrypt the DATA
Encrypted copy of Data Key is stored with the data - no separate location

for Decryption:
CMK decrypts Data Key into plain format, 
then Plain Data Key is used to decrypt data
So then at the end of the process,
the data has been decrypted and the plain text key is deleted from
memory,


Why Envelpe Encryption?......

the main reason is for "network performance" because when you encrypt that
data directly with KMS, that data needs to be transferred over the network into the KMS service and with envelopes encryption,
only the data key goes over the network and not your data and then the data key is used locally in your application or AWS service,
avoiding the need to transfer lots of data over the network to
KMS. So if we're talking about gigabytes or terabytes of data,
we don't want to send that over the network to KMS.
Even if it's going over the Amazon network,
it's just not going to be efficient or performance.
So instead with envelope encryption,
it's only the data key that gets sent over the network to KMS and your data
doesn't move anywhere.


AWS Certificate Manager 
SSL/TLS 
However, one thing to be aware
of if you are using AWS Certificate Manager with CloudFront
then you must create the certificate
in the US East one region

--------------------------------------------------------------------------
You are working on a project which requires a key management solution. Your security architect has confirmed that a multi-tenant solution is fine. Which solution do you recommend?


S3 encryption


Client-side encryption


CloudHSM


KMS

Good work!
KMS is multi-tenant, whereas CloudHSM is dedicated hardware. S3 encryption and client-side encryption are not key management solutions.

---------------------------------------------------------------------------
---------------------------AWS Certificate Manager

ACM handles complexity of creating and managing public SSL/TLS certificates for your aws based websites and applications 

ACM handles two kinds of certificates 
1- PUBLIC - free provided by ACM (including Lets encrypt)
2- PRIVATE - certificates you import ($400 / month)

ACM can handle multiple subdomains and wildcard domains (*)
dhamaps.com 
*.dhamaps.com 

ACM can only be attached too:
````````````ELASTIC LOAD BALANCER
````````````CloudFront
````````````API Gateway
````````````Elastic Beanstalk (through Elastic Load Balancer)

Cannot be attached to individual EC2 instances

TERMINATING SSL at the Load Balancer 
                                ACM
                                 |
internet-------->Route 53-----> ALB-------->multiple EC2 instances
- - - - encrypted - -  - - - - - --  not encrypted

                                            let's encrypt
                                                |
internet-------->Route 53-----> ALB-------->multiple EC2 instances
- - - - encrypted - -  - - - - - -- - - - - - - - --encrypted
manual set up .complex. dnt need you private environment encrypted anyway'


SSL/TLS provides encryption for sensitive data in transit and authentication using certificates to establish the identity of your site and to secure connections between browsers, applications, and your site. ACM provides an easy way to provision and manage these certificates so that you can configure a website or application to use the SSL/TLS protocol. 

AWS Private Certificate Authority (CA) provides you a highly available private certificate authority service without the upfront investment and ongoing maintenance costs of operating your own private CA. AWS Private CA allows developers to be more agile by providing them APIs to create and deploy private certificates programmatically. You also have the flexibility to create private certificates for applications that require custom certificate lifetimes or resource names. 

ACM helps manage the challenges of maintaining SSL/TLS certificates, including certificate renewals, so you don’t have to worry about expiring certificates.
--------------------------------------------------------------------------
----------------------------Route 53 
[ROUTE 53]
amazons DNS service
Maps ip,s3 bucket, load balancer to domain name
Hosted Zone - container for DNS records for your domain
Alias - allows you to route traffic to top of DNS Namespace dhamaps.com

                 |---app.pro.com ---------> ELB
                 |---ami.pro.com ---------> EC2 instance
Route 53--------->---api.pro.com ---------> API Gateway
                 |---www.pro.com ---------> CloudFront
                 |___minecraft.pro.com  --> elastic IP 2.213.54.67

You create custom subdomains by CREATING RECORD SETS (Alias)
Aliases are SMART, they can detect change in public IP of AWS Resource and keep that endpoint pointed to the correct resource
Always use Alias
e.g. we can point www subdomain using an A record to point to specific IP

Routing Policies:
7 Types of Routing Policies 
1- Simple R - multiple addresses result in random selection
2- Weighted R - route traffic based on weighted values to split traffic
3- Latency-based R - route traffic to region resource with lowest latency
4- Failover R - route traffic if primary endpoint is unhealthy
5- Geolocation R - route based on location of your users
6- Geo-Proximity R - route based on location of your resources,busy to idle
7- Multi-value Answer R respond to DNS queries with upto eight healthy records selected at random - exactly like Simple R but with health checks

Create Sophisticated Routing Policies based on Visuals 
==== Route-53-Traffic-Flow
$50 per policy record / month
supports versioning so you can roll out or roll back updates


6- Geo-Proximity R - route based on location of your resources,busy to idle
Only be created through Traffic-flow  visualized 
boudary based, 
you create boundaries between regions through selecting as much as regions
you give them a bias rating, from -99 to 99
you can also provide custom cordinates over region



Route 53 Health Checks 
$0.50 per health check per month for aws endpoints 
$0.750 per health check per month for non aws endpoints 
for extra features: $1 / month (https, string matching, fast interval, latency measurement)
can create upto 50 health checks for aws endpoints within or linked to same aws account
health checks every 30s by default, can be reduce to every 10s 
a health check can initialize a failover if status is returned unhealthy 
a cloudwatch alrm can be created to alert you 
a health check can monitor other health checks to create a chain of reactions


Route 53 Resolver  (formerly known as .2 resolver)
DNS resolution for Hybrid Environments (on-premise and cloud)
A regional service that lets you route DNS queries b/w ur VPC and ur Network
Direction of Queries:
inbound and outbound - 
       configure endpoints that allow DNS queries both to and from your VPC
       aws vpc<-> local network
inbound 
       configure an endpoint that allows DNS queries to your VPC from your network or another VPC 
       aws vpc<- local network
outbound
       configure an endpoint that allows DNS queries from your VPC from your network or another VPC
       aws vpc-> local network



Comparison of alias and CNAME records
Alias records are similar to CNAME records, but there are some important differences. The following list compares alias records and CNAME records.

Resources that you can redirect queries to
Alias records
An alias record can only redirect queries to selected AWS resources, such as the following:

Amazon S3 buckets

CloudFront distributions

Another record in the same Route 53 hosted zone

For example, you can create an alias record named acme.example.com that redirects queries to an Amazon S3 bucket that is also named acme.example.com. You can also create an acme.example.com alias record that redirects queries to a record named zenith.example.com in the example.com hosted zone.

CNAME records
A CNAME record can redirect DNS queries to any DNS record. For example, you can create a CNAME record that redirects queries from acme.example.com to zenith.example.com or to acme.example.org. You don't need to use Route 53 as the DNS service for the domain that you're redirecting queries to.

Creating records that have the same name as the domain (records at the zone apex)
Alias records
In most configurations, you can create an alias record that has the same name as the hosted zone (the zone apex). The one exception is when you want to redirect queries from the zone apex (such as example.com) to a record in the same hosted zone that has a type of CNAME (such as zenith.example.com). The alias record must have the same type as the record you're routing traffic to, and creating a CNAME record for the zone apex isn't supported even for an alias record.

CNAME records
You can't create a CNAME record that has the same name as the hosted zone (the zone apex). This is true both for hosted zones for domain names (example.com) and for hosted zones for subdomains (zenith.example.com).

Pricing for DNS queries
Alias records
Route 53 doesn't charge for alias queries to AWS resources. For more information, see Amazon Route 53 Pricing.

CNAME records
Route 53 charges for CNAME queries.'





-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
5-5-5-5-5-5-5-5-5-5-5-5-5-5-5--5-5-5-5-5------INCIDENT RESPONSE
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-
There are obvious differences between environments built to run in the cloud and environments running on premises. When it comes to incident response, the same can be said. For example, the prepare and practice aspects of incident response can be done more efficiently on AWS. Incident response in the AWS Cloud is faster, cheaper, more effective, and simpler to manage. With AWS, you can significantly enhance your ability to detect, react, and recover. Some capabilities for investigation are possible only by using AWS. 

RECOMMENDED PRACTICES.
---------------------=============---------------------------
Using APIs for automation
In AWS, you can use APIs to automate many of the routine tasks that need to be performed during incident response. For example, using a single command, you can isolate an instance by changing the security groups associated with the instance. 
---------------------=============---------------------------
Performing forensics on data volumes
Forensics often requires capturing the disk image or as-is configuration of an operating system. You can use Amazon Elastic Block Store (Amazon EBS) snapshots and the Amazon Elastic Compute Cloud (Amazon EC2) APIs to capture the data and state of systems under investigation.
---------------------=============---------------------------
Operating in a clean room
AWS CloudFormation can be used to quickly create a new, trusted environment in which to conduct deeper investigation. AWS CloudFormation can deploy preconfigured instances in an isolated environment. These instances may contain all the necessary tools forensic teams need to determine the cause of the incident.
---------------------=============---------------------------
Coordinating AWS services into serverless workflows
AWS Step Functions lets you coordinate multiple AWS services into serverless workflows so you can build and update apps quickly. Workflows are made up of a series of steps, with the output of one step acting as the input into the next. Step Functions can be used to design and run workflows that stitch together services such as AWS Lambda and AWS CloudFormation to respond to an incident in the cloud.
---------------------=============---------------------------

---------------------=============---AWS CONFIG.------------------------
---------------------=============---AWS CONFIG.------------------------
---------------------=============---AWS CONFIG.------------------------

Service features and benefits


Continuously Monitor.
With AWS Config, you are able to "continuously monitor" and record configuration changes of your AWS resources.

Continuously Audit And Assessment.
AWS Config allows you to "continuously audit and assess" the overall compliance of your AWS resource configurations with your organization’s policies and guidelines. 

Change Management.
With AWS Config, you are able to track the relationships among resources and review resource dependencies prior to making "changes"

bullet
AWS Config enables you to capture a comprehensive history of your AWS resource configuration changes to simplify "troubleshooting of your operational issues."

Compliance as Code. in aws lambda
Security Analysis.

SETUP:
1- Specify AWS resource you want aws Config to record
2- Set up Amazon S3 bucket to receive Configuration snapshots
3- Set up Amazon SNS Topic to stream notifications
4- Grant aws Config permissions to acces S3 and SNS
5- Specify rules that you want aws config to use to evaluate compliance information for the recorded resource type.

e.g. you setup with pre-built aws managed RULE that your "desired-EC2-Instance-Type" is t2.small...
in your environment, when anyone creates an instance other than that, you will instantly know, it will show you which instances are non-compliant


Use case: responding to configuration changes

You can use AWS Config to respond to unwanted configuration changes. AWS Config runs evaluations when certain types of resources are created, changed, or deleted. You choose which resources trigger the evaluation by defining the rule's scope. AWS Config invokes an AWS Lambda function when it detects a configuration change.



---------------------------------------------------
AWS Well-Architected Tool
The AWS Well-Architected Tool is a self-service tool that is designed to help customers review AWS workloads at any time without the need for an AWS solutions architect. By using this tool, you can review your workloads using a consistent process, understand potential risks in your workload architectures, and identify next steps for improvement. 

First, define your workload, and then answer a set of questions across the six pillars of the AWS Well-Architected Framework: operational excellence, security, reliability, performance efficiency, and cost optimization. The AWS WA Tool then provides a plan describing the improvements that can be applied to the workload. There’s no charge for the AWS WA Tool; you pay only for any AWS resources that you consume. However, the tool is available only in select Regions. Check the FAQs for more information.'

Operational excellence
This pillar focuses on running and monitoring systems to deliver bus.

Security
This pillar focuses on protecting information and systems.

Reliability
This pillar focuses on the ability to prevent and quickly recover from failures.

Performance efficiency
This pillar focuses on using IT and computing resources efficiently.

Cost optimization
This pillar focuses on avoiding unneeded costs.

-------------------------------------------------------------------------------
Which AWS service allows you to analyze, investigate, and identify the root cause of potential security issues or suspicious activities in your account?

AWS Resource Access Manager

Correctly selected
"Amazon Detective"

Correctly unselected
Amazon Macie

Correctly unselected
Amazon GuardDuty

---------------------------------------------------------------------------
A company wants to store sensitive user data in Amazon S3 and encrypt this data at rest. The company must manage the encryption keys and use Amazon S3 to perform the encryption. Which solution meets these requirements?

Use the option for server-side encryption with customer-provided encryption
keys (SSE-C) to configure default encryption for the Amazon S3 bucket.

Use an encryption key to configure client-side encryption. Upload the encrypted object to the Amazon S3 bucket.

Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3)
to configure server-side encryption. Upload an object to the Amazon S3 bucket.
"
Use server-side encryption with customer-provided encryption keys (SSE-C) to configure server-side encryption. Upload an object to the Amazon S3 bucket."

---------------------------------------------------------------------------
An application uses the PutObject operation in parallel to upload hundreds of thousands of objects per second to an S3 bucket. To meet security compliance, the developer uses the server-side encryption in AWS KMS (SSE-KMS) to encrypt objects as they get stored in the S3 bucket. There is a noticeable performance degradation after making the change.

Which of the following is the most likely cause of the problem?

(view)	1	0	1	00:04:44	
 The Amazon S3 throttles the PutObject operation for objects encrypted with SSE-KMS.
 The API request rate has exceeded the quota for AWS KMS API operations.```````````````````````````
 The CMK is using an AES 256 algorithm, which makes the encryption process slower. AES 128 should be used instead.
 The KMS is not using an alias to easily identify the CMK required for the server-side encryption with AWS KMS (SSE-KMS.)
AWS KMS establishes quotas for the number of API operations requested in each second.

You can make API requests directly or by using an integrated AWS service that makes API requests to AWS KMS on your behalf. The quota applies to both kinds of requests.

For example, you might store data in Amazon S3 using server-side encryption with AWS KMS (SSE-KMS). Each time you upload or download an S3 object that's encrypted with SSE-KMS, Amazon S3 makes a GenerateDataKey (for uploads) or Decrypt (for downloads) request to AWS KMS on your behalf. These requests count toward your quota, so AWS KMS throttles the requests if you exceed a combined total of 5,500 (or 10,000 or 30,000 depending upon your AWS Region) uploads or downloads per second of S3 objects encrypted with SSE-KMS.

Hence, the correct answer is: The API request rate has exceeded the quota for AWS KMS API operations.'
======================================================================
A company is developing a Python application that submits data to an Amazon DynamoDB table. The company requires client-side encryption of specific data items and end-to-end protection for the encrypted data in transit and at rest.

Which combination of steps will meet the requirement to encrypt specific data items? (Select TWO.)

Report Content Errors

A``````````````````
Generate symmetric encryption keys with AWS Key Management Service (AWS KMS).
Correct. When you configure the DynamoDB Encryption Client to use AWS KMS, the DynamoDB Encryption Client uses a KMS key that is always encrypted when the key is used outside of AWS KMS. This cryptographic materials provider returns a unique encryption key and a signing key for every table item. This method of encryption uses a symmetric KMS key.

B
Generate asymmetric encryption keys with AWS Key Management Service (AWS KMS).

C```````````````````````
Use generated keys with the DynamoDB Encryption Client.
Correct. When you configure the DynamoDB Encryption Client to use AWS KMS, the DynamoDB Encryption Client uses a KMS key that is always encrypted when the key is used outside of AWS KMS. This cryptographic materials provider returns a unique encryption key and a signing key for every table item. This method of encryption uses a symmetric KMS key.


D
Use generated keys to configure DynamoDB table encryption with AWS managed KMS keys.

E
Use generated keys to configure DynamoDB table encryption with AWS owned KMS keys.

================================================================================================================
A cryptocurrency exchange portal has a key management service hosted in their on-premises data center, which stores encryption keys and uses an RSA asymmetric encryption algorithm. The company has recently implemented a hybrid cloud architecture in AWS and you were assigned to migrate the exchange portal to their cloud infrastructure. For security compliance, the keys should be stored in dedicated, third-party validated hardware security modules under your exclusive control.

Which of the following is the BEST solution that you should implement to meet the above requirement?

Import the encryption keys from your on-premises key management service to AWS CloudHSM.````````````````````````
Develop a custom key management service using the AWS Encryption SDK.
Use AWS KMS to store and manage the encryption keys.
Import the encryption keys from your on-premises key management service to AWS Secrets Manager as Customer Master Keys (CMKs).
Incorrect
AWS CloudHSM provides hardware security modules in AWS Cloud. A hardware security module (HSM) is a computing device that processes cryptographic operations and provides secure storage for cryptographic keys.



When you use an HSM from AWS CloudHSM, you can perform a variety of cryptographic tasks:

– Generate, store, import, export, and manage cryptographic keys, including symmetric keys and asymmetric key pairs.

– Use symmetric and asymmetric algorithms to encrypt and decrypt data.

– Use cryptographic hash functions to compute message digests and hash-based message authentication codes (HMACs).

– Cryptographically sign data (including code signing) and verify signatures.

– Generate cryptographically secure random data.

 

You should consider using AWS CloudHSM instead of AWS KMS if you require:

– Keys stored in dedicated, third-party validated hardware security modules under your exclusive control.

– FIPS 140-2 compliance.

– Integration with applications using PKCS#11, Java JCE, or Microsoft CNG interfaces.

– High-performance in-VPC cryptographic acceleration (bulk crypto).

 

Hence, the correct answer is to import the encryption keys from your on-premises key management service to AWS CloudHSM.

Using AWS KMS to store and manage the encryption keys is incorrect. Although AWS KMS supports asymmetric encryption, it doesn’t provide dedicated, third-party validated hardware security modules which are under your exclusive control. You have to use CloudHSM instead.

Importing the encryption keys from your on-premises key management service to AWS Secrets Manager as Customer Master Keys (CMKs) is incorrect because you can’t store CMKs to AWS Secrets Manager.

Developing a custom key management service using the AWS Encryption SDK is incorrect because this entails a lot of effort to implement. Moreover, the AWS Encryption SDK only encrypts your data using a symmetric key algorithm which doesn’t comply with the requirements provided in the scenario.

===============================================================================================================
A developer is designing a multi-tiered system which utilizes various AWS resources. The application will be hosted in Elastic Beanstalk, which uses an RDS database and an S3 bucket that is configured to use Server-Side Encryption with Customer-Provided Encryption Keys (SSE-C). In this configuration, Amazon S3 does not store the encryption key you provide but instead, stores a randomly salted hash-based message authentication code (HMAC) value of the encryption key in order to validate future requests.

Which of the following is a valid consideration that the developer should keep in mind when implementing this architecture?

If you lose the encryption key, the salted HMAC value can be used to decrypt the object.
The salted HMAC value can be used to decrypt the contents of the encrypted object.
If you lose the encryption key, you lose the object.```````````````````````````````````````
The salted HMAC value can be used to derive the value of the encryption key.
Correct
Server-side encryption is about protecting data at rest. Using server-side encryption with customer-provided encryption keys (SSE-C) allows you to set your own encryption keys. With the encryption key you provide as part of your request, Amazon S3 manages both the encryption, as it writes to disks, and decryption, when you access your objects. Therefore, you don’t need to maintain any code to perform data encryption and decryption. The only thing you do is manage the encryption keys you provide.



When you upload an object, Amazon S3 uses the encryption key you provide to apply AES-256 encryption to your data and removes the encryption key from memory. It is important to note that Amazon S3 does not store the encryption key you provide. Instead, it is stored in a randomly salted HMAC value of the encryption key in order to validate future requests. The salted HMAC value cannot be used to derive the value of the encryption key or to decrypt the contents of the encrypted object. That means, if you lose the encryption key, you lose the object.

When you retrieve an object, you must provide the same encryption key as part of your request. Amazon S3 first verifies that the encryption key you provided matches, and then decrypts the object before returning the object data to you.

================================================================================================================
A company uses AWS Systems Manager (SSM) Parameter Store to manage configuration details for multiple applications. The parameters are currently stored in the Standard tier. The company wants its operations team to be notified if there are sensitive parameters that haven’t been rotated within 90 days.

Which must be done to meet the requirement?


Convert the sensitive parameters from Standard tier into Advanced tier. Set a ExpirationNotification policy with a value of 90 days. Use Amazon EventBridge (Amazon CloudWatch Events) to send a notification via Amazon SNS.

Configure a NoChangeNotification policy with a value of 90 days. Use Amazon EventBridge (Amazon CloudWatch Events) to send a notification via Amazon SNS.
Set up an Amazon EventBridge (Amazon CloudWatch Events) event pattern that captures SSM Parameter-related events. Use Amazon SNS to send notifications.

/Convert the sensitive parameters from Standard tier into Advanced tier. Set a NoChangeNotification policy with a value of 90 days. Use Amazon EventBridge (Amazon CloudWatch Events) to send a notification via Amazon SNS./