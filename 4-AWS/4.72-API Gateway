=======================================================================
-----------------------------------------------------------------------
=======================================================================
API : Application Programming Interface 
we use APIs to interact with web applications 
Applications use APIs to communicate with each other
APIs are mechanisms that facilitate two software components communicating with each other. APIs act as the front door for applications to access data, business logic, or functionality from backend services. 
2015
REST APIs Introduced
Resource + verb
Customers + GET, POST, etc..
first 333 million requests = $3.5/month/million

2018
WebSocket APIs Introduced
Duplex communication
Connection based
Use Case Specific


2020
HTTP APIs Introduced
Resource + verb OR rpc
Parity is coming...
Lightweight
cheap
first 300 million requests = $1/month/million
70% cheaper than REST

Feature                         REST.                           HTTP.
Usage Plans & API Keys                                          X
API Caching                                                     X
Testing / Mocking                                               X
Request Validation &                                            X
Transformation
Native OIDC / OAuth 2.0         X(use Lambda Authorizers)
ALB Integrations                X


o
o
o
How to Switch from REST to HTTP
Export your API Definitions using Swagger/OpenAPl
Import them into new HTTP APIs
Largely 1:1 changeover, but feature discrepancy will be highlighted


TLDR
Use HTTP everytime, except when the feature isn't supported


USING HTTP API GATEWAY TO CALL A LAMBDA FUNCTION
BOTH GET & POST REQUEST


import json
import uuid

GET_RAW_PATH = "/getPerson"
CREATE_RAW_PATH = "/createPerson"

def lambda_handler(event, context):
    if event['rawPath'] == GET_RAW_PATH:
       #GetPerson Path - what happens?
       print('Start request for GetPerson')
       personId = event['queryStringParameters']['personId']
       print('Received Request with personId= ' + personId)
       return {"firstName": "azam", "lastName": "sajjad", "email": "azams@mail.com"}
       
    elif event['rawPath'] == CREATE_RAW_PATH:
        #CreatePerson Path - what happens?
        decodedEvent = json.loads(event['body'])
        firstName = decodedEvent['firstName']
        print('Received Request with firstName= ' + firstName)
        # call database - NOT DOING IT HERE
        return { "personId": str(uuid.uuid1())}

'
-----------------------------------------------------
API GATEWAY CACHING:
CACHES your endpoints response (this reduces no. of calls made to endpoint)
TTL (when u enable caching, api gateway caches responses from endpoints for a specified TTL, default is 300 seconds)
API GATEWAY returns cached response to new requests, instead of making new request to endpoint. 
THIS REDUCES LATENCY

API GATEWAY THROTTLING is to prevent your API from being overwhelmed by too many requests
by-default, API Gateway limits the steady-state request rate to 10,000 requests per second,per region.
by-default, API Gateway limits the concurrent request to 5,000 across all APIs per second,per region.
if you exceed any of these limits, you get 429 ERROR (Too Many Requests)

Throttling Example 
5,000 requests in 1st millisecond 
5,000 requests evenly spread across 999 milliseconds
this is within limits of 10,000 req per second and 5,000 concurrent request
this will happen without any errors
-------------------------------------------------------------------
======================="API Gateway features"===========================

----------------"Developer features in API Gateway"----------------------

"Run multiple versions of an API at the same time"
With API Gateway, you can run multiple versions of the same API simultaneously so that you can quickly iterate, test, and release new versions. You can make changes to your API and host multiple versions of it for different users also.

"Quick SDK generation"
If you’re using REST APIs, API Gateway can generate client Software Development Kits (SDKs) for several platforms, which you can use to quickly test new APIs from your applications and distribute SDKs to third-party developers. 
The generated SDKs handle API keys and sign requests using AWS credentials. API Gateway can generate client SDKs for Java, JavaScript, Java for Android, Objective-C or Swift for iOS, and Ruby. You can use AWS Command Line Interface (AWS CLI) to generate and download an SDK of an API for a supported platform by calling the get-sdk command.

"Transform or validate request-response data"
With API Gateway, you can also transform and validate both incoming and outgoing requests. With this feature, you can use API Gateway as a fully managed environment for transforming requests as they come into your API before they are passed to your backend.

-------------"Features for managing API access"------------------------

There are also some important features for managing API access. To learn more, expand each of the following three categories.


"Reduce latency and throttle traffic"
API Gateway provides end users with the lowest possible latency for API requests and responses by taking advantage of the Amazon CloudFront global network of edge locations. With this service, you also can throttle traffic and authorize API calls to ensure that backend operations withstand traffic spikes and backend systems are not unnecessarily called.


"Built-in, flexible authorization option"
API Gateway gives you several options for authorization. You can authorize access to your APIs with AWS Identity and Access Management (IAM) and Amazon Cognito. If you use OAuth tokens, API Gateway also offers native OpenID Connect (OIDC) and OAuth 2 support. 
To support custom authorization requirements, you can invoke a Lambda authorizer from Lambda. With a Lambda authorizer, you can develop your own authorization code using a custom Lambda function.

"API keys for third-party developers"
If you’re using REST APIs, API Gateway helps you manage the ecosystem of third-party developers accessing your APIs. You can create API keys on API Gateway, set fine-grained access permissions on each API key, and distribute them to third-party developers to access your APIs. API keys are not a primary authorization mechanism for your APIs, but provide you the ability to track usage for specific users or services.

========================================================================
REST APIs are intended for APIs that require API proxy functionality and API management features in a single solution. HTTP APIs are optimized for building APIs that proxy to Lambda functions or HTTP backends, making them ideal for serverless workloads. HTTP APIs are a cheaper and faster alternative to REST APIs, but they do not currently support API management functionality. Unlike a REST API, which receives and responds to requests, a WebSocket API supports two-way communication between client apps and your backend. The backend can send callback messages to connected clients.

API Gateway integration types

When you choose an integration type, that determines how method request data is passed to the backend. As part of creating the method, you must choose an integration type. To learn more, expand each of the following five categories.


Lambda Function
    When you are using API Gateway as the gateway to a Lambda function, you’ll use the Lambda integration. This will result in requests being proxied to Lambda with request details available to your function handler in the event parameter, supporting a streamlined integration setup. The setup can evolve with the backend without requiring you to tear down the existing setup.

    For integrations with Lambda functions, you will need to set an IAM role with required permissions for API Gateway to call the backend on your behalf.


HTTP Endpoint
    HTTP integration endpoints are useful for public web applications where you want clients to interact with the endpoint. This type of integration lets an API expose HTTP endpoints in the backend.

    When the proxy is not configured, you’ll need to configure both the integration request and the integration response, and set up necessary data mappings between the method request-response and the integration request-response.

    If the proxy option is used, you don’t set the integration request or the integration response. API Gateway passes the incoming request from the client to the HTTP endpoint and passes the outgoing response from the HTTP endpoint to the client.

AWS Service
    AWS Service is an integration type that lets an API expose AWS service actions. For example, you might drop a message directly into an Amazon Simple Queue Service (Amazon SQS) queue.

Mock
    Mock lets API Gateway return a response without sending the request further to the backend. This is a good idea for a health check endpoint to test your API. Anytime you want a hardcoded response to your API call, use a Mock integration.

VPC Link
    With VPC Link, you can connect to a Network Load Balancer to get something in your private VPC. For example, consider an endpoint on your EC2 instance that’s not public. API Gateway can’t access it unless you use the VPC link and you have to have a Network Load Balancer on your backend.

    For an API developer, a VPC Link is functionally equivalent to an integration endpoint.

========================================================================
    Testing a method with the API Gateway console is the same as calling the method outside of the API Gateway console. Changes can’t be undone. For example, if you use the API Gateway console to call a method that deletes an API's resources, if the method call is successful, the API's resources will be deleted.
========================================================================
WebSocket APIs are often used in real-time application use cases such as:

Chat applications
Streaming dashboards
Real-time alerts and notifications
Collaboration platforms
Multiplayer games
Financial trading platforms

PRICING

FLAT CHARGE
WebSocket APIs for API Gateway charge for the messages you send and receive. You can send and receive messages up to 128 KB in size. Messages are metered in 32-KB increments, so a 33-KB message is charged as two messages.
For WebSocket APIs, the API Gateway free tier currently includes one million messages (sent or received) and 750,000 connection minutes for up to 12 months.

CONNECTION MINUTES
In addition to paying for the messages you send and receive, you are also charged for the total number of connection minutes.

ADDITIONAL CHARGES
You may also incur additional charges if you use API Gateway in conjunction with other AWS services or transfer data out of AWS.
========================================================================
===========Maintaining connections to WebSocket APIs====================
There are three predefined routes that can be used with WebSocket APIs: $connect, $disconnect, and $default. In addition to the predefined routes, you can also create custom routes.


To understand how the WebSocket connections are maintained, you need to understand how the client connects, sends messages, and disconnects from the API. To learn more, expand each of the following three categories.


Connect
–
The client apps connect to your WebSocket API by sending a WebSocket upgrade request. If the request succeeds, the $connect route is invoked while the connection is being established. Until the invocation of the integration you associated with the $connect route is completed, the upgrade request is pending and the actual connection will not be established. If the $connect request fails, the connection will not be made.


Established connection
–
After the connection is established, your client's JSON messages can be routed to invoke a specific backend service based on message content. When a client sends a message over its WebSocket connection, this results in a route request to the WebSocket API. The request will be matched to the route with the corresponding route key in API Gateway. 


Disconnect
–
The $disconnect route is invoked after the connection is closed. The connection can be closed by the server or by the client. As mentioned earlier in the lesson, since the connection is already closed when it is invoked, the $disconnect route is a best-effort event. API Gateway will try its best to deliver the $disconnect event to your integration, but it cannot guarantee delivery. The backend can initiate disconnection by using the @connections API. '
-------------------------------------------------------------------------
=====================TYPES REST APIs====================================
Regional endpoint
Provides lower latency for applications that invoke your API within the same AWS Region

Edge-optimized endpoint
Deploys a fully managed Amazon CloudFront distribution

Private endpoint
Requests are only routable within a single virtual private cloud (VPC) that you control

The API Gateway optional cache configuration is only available for REST APIs.
Q
Which of the following REST API endpoint type changes is not supported by API Gateway? Select the correct answer and choose SUBMIT. 
From private to edge-optimized
-----------------------------------------------------------------------
You can also define usage  plans that set throttling and request quota limits for each API key. The use of API keys is optional.

Using API Gateway as the front door for APIs

Before diving into how to design and deploy APIs in API Gateway, you need to understand what API Gateway is. API Gateway is a service that facilitates the creation, publishing, maintenance, monitoring, and security of your APIs at any scale. API Gateway handles all your tasks around accepting and processing hundreds of thousands of concurrent API calls. This includes handling traffic management, Cross Origin Resource Sharing (CORS) support, authorization and access control, throttling, monitoring, and API version management. 



API GATEWAY : is serverless, supports throttling, logged to CloudWatch
API GATEWAY provides endpoints for your apps running in aws
publish maintain and monitor APIs 
API TYPES :
RESTful APIs are optimized for stateless, serverless workloads
REST=REpresentational State Transfer, supports JSON
Websocket APIs are for real-time, two-way, stateful communication e.g. chat apps
users -> API GATEWAY -> Lambda
users -> API GATEWAY -> EC2
users -> API GATEWAY -> DynamoDB

$LATEST is the latest version of code you uploaded into lambda 
how to version control 
upload code > action > publish new version > create alias 
(weighted traffic routing also supported between versions)

Concurrent Execution Limit is 1000 functions per region per account
HTTP status code 429
you can also reserve some concurrency for critical lambda functions
they will be prioritized
but it also sets limit for that function.e.g if you reserve 500 simultaneous function execution for a particular function, it will never go beyond 500 concurrent runs

LAMBDA and VPC Access 
it is possible to enable lambda access resources that are inside private VPC
these resources can be EC2/RDS/etc
Lambda creates ENIs using IP from private subnets
configuration > permissions > Execution role url
AWSLambdaVPCAccessExecutionRole (add this policy for lambda to access VPC)

e.g.
A company is using AWS Lambda to process small number of images that are uploaded to Amazon S3. Suddenly, they uploaded a large number of image files (several thousands) in S3 bucket. As a result, an error was generated by AWS Lambda (status code 429).


What is the MOST likely cause of this error?


"The concurrency execution limit for the account has been exceeded."

Amazon S3 could not handle the sudden burst in traffic.

AWS Lambda cannot process multiple files simultaneously

The event source mapping has not been configured.


===========================================================================

API GATEWAYS (ADVANCED)

SOAP - legacy protocol - returns a response in XML format instead of JSON
        came out in 1990s - you can configure API Gateway as a SOAP web service passthrough - how?
        https://www.rubix.nl/blogs/how-configure-amazon-api-gatewaysoap-        webservice-passthrough-minutes
REST - Latest protocol

IMPORT APIs
You can use the API Gateway Import API feature to import an API from an
external definition file into API Gateway. Currently, the Import API feature supports Swagger v2.0 definition files. aka OpenAPI
With the Import API, you can either create a new API by submitting
a POST request that includes a Swagger definition in the payload and
endpoint configuration, or you can update an existing API by using a PUT
request that contains a Swagger definition in the payload. You can update
an API by overwriting it with a new definition, or merge a definition with an
existing API. You specify the options using a mode query parameter in the
request URL .
Import


API THROTTLING
By default, API Gateway limits the steady-state request rate to
10,000 requests per second (rps).
The maximum concurrent requests is 5000 requests across all
APIs within an AWS account.
If you go over 10,000 requests per second or 5000 concurrent
requests you will receive a 429 Too Many Request error
response.
API
Import API’s using Swagger 2.0 definition files
• API Gateway can be throttled
• Default limits are 10,000 RPS or 5000 concurrently
• You can configure API Gateway as a SOAP Webservice   
passthrough
--------------------------------------------------
API GATEWAY MOCK ENDPOINTS
Create, Test, Debug
backend is not ready yet but you want to test some new website features
e.g. cart,payment
allows team to continue development without depending on backend to be build
API GATEWAY RESPONSE - 
You definee the response 
status code and message 
forms the mock integration response 
---------------------------------------------------
API GATEWAY STAGEs 
Differentiate your APIs with stages
Some options for you to differentiate your APIs with stages include:

Use different stages by environment or customer.
Use stage variables to increase deployment flexibility.
Use stages with canary deployments to test new versions.

A stage is a snapshot of the API that represents a unique identifier for a version of a deployed API. With stages, you can have multiple versions and roll back versions. Anytime you update anything about the API, you need to redeploy it to an existing stage or to a new stage that you create as part of the deploy action.


references the lifecycle state of the API e.g. dev,prod 
Each stage can be associated with a different endpoint e.g. dev,prod
each stage has a unique invoke url e.g. 
https://dwncjrevn.execute-api.us-east-1.amazonaws.com/dev 
https://dwncjrevn.execute-api.us-east-1.amazonaws.com/prod
        API ID                                      Stage name

if we have 2 lambda functions, dev&prod, we can create API gateway with dev&prod stage 


LAB Creating Stages 
Create 2 functions stageDevevFunction,stageProdFunction with following code 
// export const handler = async (event) => {
//   // TODO implement
//   const response = {
//     statusCode: 200,
//     body: JSON.stringify('This is my Prod/Dev function'),
//   };
//   return response;
// };
goto API Gateway
BUILD REST API --> NewAPI & name=MyAPI -> Create API
ACTION->CREATE METHOD->"GET"->Lambda Function = ${stageVariables.lmbfunction}->
it gives you a command to run in cloudshell 
// aws lambda add-permission --function-name "arn:aws:lambda:us-east-1:965329023955:function:myprod/devfunction" --source-arn "arn:aws:execute-api:us-east-1:965329023955:nzxaisdv5m/*/GET/" --principal apigateway.amazonaws.com --statement-id 0e68dff5-42c2-4116-81f7-a26a4ae2a2bc --action lambda:InvokeFunction
save 
ACTION->DEPLOY API->newstage(test)
CREATE->prod 
STAGE VARIABLE->key=lmbfunction value=stageProdFunction
CREATE->dev
STAGE VARIABLE->key=lmbfunction value=stageDevFunction

Simplify version management with stage variables

As you define variables in the stage settings in the console, you can reference them with the $stageVariables.[variable name] notation. You can also inject stage-dependent items at runtime such as:

URLs
Lambda functions
Any necessary variables

This is a great way for you to perform actions such as invoking different endpoints and different backends for different stages. For example, if you have different endpoints with different URLs or different Lambda function aliases based on environment, you can use stage variables to inject those variables.

Name                Value
lambdaFn            myLarnbdaFn:demo
url                 http://www.myendpoint.com/demo

Name                Value
lambdaFn            myLarnbdaFn:prod
url                 http://www.myendpoint.com/prod

-----------------------------------------------------
Creating METHODS Setup 

Lambda Function Integration
The first integration point is integrating with a
Lambda Function type. Rather than specifying the
function name in the setup, the stage variable
notation is used with the lambdaFn variable.

Lambda Integration 
Lambda Function = ${StageVariables.LambdaFn}

HTTP Integration
Endpoint URL = $(stageVariables.url}

By performing these actions, at runtime, the proper value is retrieved dynamically for both of those variables. Using stage variables is especially valuable as you move toward an automated continuous integration and continuous delivery (CI/CD) pipeline.
-----------------------------------------------------
Building AND Deploying best practices

Now that you understand how to build and deploy an API into API Gateway, here are some best practices for you to consider using in your API Gateway architecture.

Use API Gateway stages with Lambda aliases - - - - - - - - -

To highlight something that was mentioned in the previous example, Lambda and API Gateway are both designed to support flexible use of versions. You can do this by using aliases in Lambda and stages in API Gateway. When you couple that with stage variables, you dont have to hard-code components, which leads to having a smooth and safe deployment.

----> In Lambda, enable versioning and use aliases to reference.
----> In API Gateway, use stages for environments.
----> Point API Gateway stage variables at the Lambda aliases.

USE Canary deployments - - - - - - - - -

With Canary deployments, you can send a percentage of traffic to your "canary" while leaving the bulk of your traffic on a known good version of your API until the new version has been verified. API Gateway makes a base version available and updated versions of the API on the same stage. This way, you can introduce new features in the same environment for the base version.

To set up a Canary deployment through the console, select a stage and then select the Canary tab for that stage.

Consider you want to add a new GET method to a petStore API with a /store/products API resource without impacting clients. To do this, you can create a canary that sends 10 percent of traffic to the canary with the new method.

Use AWS SAM to simplify deployments - - - - - - - - -
Using AWS SAM templates
–
AWS SAM provides templates that help you define your serverless applications. These template specifications provide you with a straightforward and clean syntax to describe your functions, APIs, permissions, configurations, and events. You use an AWS SAM template file to operate on a single, deployable, versioned entity that makes up your serverless application.

Use Swagger and OpenAPI for more complex APIs - - - - - - - - -
–
AWS SAM also supports OpenAPI to define more complex APIs. This can either be 2.0 for the Swagger specification, or one of the OpenAPI 3.0 versions, like 3.0.1. OpenAPI is an industry-standard way to document and design your APIs. 
With SAM, you can document your API in an external OpenAPI or Swagger file, and then reference that in a SAM template.
-----------------------------------------------------
API RESPONSE TRANSFORMATIONS
AppFrontend->APIRequest->  APIGateway  ->APIRequest->AppBackend
                          modify Request

AppFrontend<-APIResponse<-  APIGateway  <-APIResponse<-AppBackend
                          modify Response

HTTP APIs:
parameter mapping is used to modify API requests and responses
we can change the Header, Query String, Request Path in API Request
we can change the Header, Status Code,               in API Response


------------------------------------------------------
X-Ray
X-Ray [Service Map] provides end-to-end view of API requests as they travel through your application
X-Ray can be integrated with EC2, ECS, Lambda, EB, SNS, SQS, DynamoDB, ELB, API Gateway, S3
X-Ray can be integrated with with your own application written in java, node.js, .net, go, ruby, python
X-Ray SDK automatically captures metadata for API calls made to AWS services using AWS SDK

Procedure:
Install X-Ray Agent on EC2 instance
Instrument your application using X-Ray SDK (sdk has libraries)
X-Ray sdk gathers informationfrom request and response headers, the code in your application and metadata about aws resources on which it runs and send this trace data to X-Ray e.g. HTTP requests, error codes, latency data

You need instrument(configure) both the X-Ray SDK and X-Ray Daemon on your systems
sdk sends data to daemon, which uploads them to X-Ray in batches

for docker container, install X-Ray daemon in its own docker container, and your application in its own container, all in same ECS cluster

---------------------------------------------------------------------------
-------------------------------------------------------------------
Set up a PROXY INTEGRATION with a proxy resource

To set up a proxy integration in an API Gateway API with a proxy resource, you perform the following tasks:

Create a proxy resource with a greedy path variable of {proxy+}.

Set the ANY method on the proxy resource.
- - - - - - - - - - - - - - - - - - - - - - - - 
- - - - - - - - - - - - - - - - - - - - - - - - 

Integrate the resource and method with a backend using the HTTP or Lambda integration type.
API Gateway enacts certain restrictions and limitations when handling methods with either a Lambda proxy integration or an HTTP proxy integration.
A proxy resource is most powerful when it is integrated with a backend using either HTTP proxy integration or Lambda proxy integration.
- - - - - - - - - - - - - - - - - - - - - - - - 

The HTTP proxy integration, designated by HTTP_PROXY in the API Gateway REST API, is for integrating a method request with a backend HTTP endpoint. With this integration type, API Gateway simply passes the entire request and response between the frontend and the backend, subject to certain restrictions and limitations.

Note
HTTP proxy integration supports multi-valued headers and query strings.

When applying the HTTP proxy integration to a proxy resource, you can set up your API to expose a portion or an entire endpoint hierarchy of the HTTP backend with a single integration setup. For example, suppose the backend of the website is organized into multiple branches of tree nodes off the root node (/site) as: /site/a0/a1/.../aN, /site/b0/b1/.../bM, etc. If you integrate the ANY method on a proxy resource of /api/{proxy+} with the backend endpoints with URL paths of /site/{proxy}, a single integration request can support any HTTP operations (GET, POST, etc.) on any of [a0, a1, ..., aN, b0, b1, ...bM, ...]. If you apply a proxy integration to a specific HTTP method, for example, GET, instead, the resulting integration request works with the specified (that is, GET) operations on any of those backend nodes.
- - - - - - - - - - - - - - - - - - - - - - - - 
Lambda proxy integration with a proxy resource
The Lambda proxy integration, designated by AWS_PROXY in the API Gateway REST API, is for integrating a method request with a Lambda function in the backend. With this integration type, API Gateway applies a default mapping template to send the entire request to the Lambda function and transforms the output from the Lambda function to HTTP responses.

Similarly, you can apply the Lambda proxy integration to a proxy resource of /api/{proxy+} to set up a single integration to have a backend Lambda function react individually to changes in any of the API resources under /api.
- - - - - - - - - - - - - - - - - - - - - - - - 

Understand API Gateway Lambda proxy integration
Amazon API Gateway Lambda proxy integration is a simple, powerful, and nimble mechanism to build an API with a setup of a single API method. The Lambda proxy integration allows the client to call a single Lambda function in the backend. The function accesses many resources or features of other AWS services, including calling other Lambda functions.

In Lambda proxy integration, when a client submits an API request, API Gateway passes to the integrated Lambda function an event object, except that the order of the request parameters is not preserved. This request data includes the request headers, query string parameters, URL path variables, payload, and API configuration data. The configuration data can include current deployment stage name, stage variables, user identity, or authorization context (if any). The backend Lambda function parses the incoming request data to determine the response that it returns. For API Gateway to pass the Lambda output as the API response to the client, the Lambda function must return the result in this format.

Because API Gateway doesnt intervene very much between the client and the backend Lambda function for the Lambda proxy integration, the client and the integrated Lambda function can adapt to changes in each other without breaking the existing integration setup of the API. To enable this, the client must follow application protocols enacted by the backend Lambda function.

You can set up a Lambda proxy integration for any API method. But a Lambda proxy integration is more potent when it is configured for an API method involving a generic proxy resource. The generic proxy resource can be denoted by a special templated path variable of {proxy+}, the catch-all ANY method placeholder, or both. The client can pass the input to the backend Lambda function in the incoming request as request parameters or applicable payload. The request parameters include headers, URL path variables, query string parameters, and the applicable payload. The integrated Lambda function verifies all of the input sources before processing the request and responding to the client with meaningful error messages if any of the required input is missing.

When calling an API method integrated with the generic HTTP method of ANY and the generic resource of {proxy+}, the client submits a request with a particular HTTP method in place of ANY. The client also specifies a particular URL path instead of {proxy+}, and includes any required headers, query string parameters, or an applicable payload.

The following list summarizes runtime behaviors of different API methods with the Lambda proxy integration:

    ANY /{proxy+}: The client must choose a particular HTTP method, must set a particular resource path hierarchy, and can set any headers, query string parameters, and applicable payload to pass the data as input to the integrated Lambda function.

    ANY /res: The client must choose a particular HTTP method and can set any headers, query string parameters, and applicable payload to pass the data as input to the integrated Lambda function.

    GET|POST|PUT|... /{proxy+}: The client can set a particular resource path hierarchy, any headers, query string parameters, and applicable payload to pass the data as input to the integrated Lambda function.

    GET|POST|PUT|... /res/{path}/...: The client must choose a particular path segment (for the {path} variable) and can set any request headers, query string parameters, and applicable payload to pass input data to the integrated Lambda function.

    GET|POST|PUT|... /res: The client can choose any request headers, query string parameters, and applicable payload to pass input data to the integrated Lambda function.

===========================================================================
In Lambda proxy integration, when a client
submits an API request, API Gateway passes
to the integrated Lambda function the raw
request as is, except that the order of the
request parameters is not preserved.


API GATEWAY - SERVICE PROXY.

OLD WAYS:
browser -> API Gateway -> Lambda (to parse payload) -> DynamoDB (POST,GET)

WITH SERVICE PROXY:
browser -> API Gateway  -> DynamoDB (POST,GET)

LAB:
1-Setup DynamoDB Customers table
                            
2-Create API Gateway Endpoint --> STAGE
                            |___> API

3-Configure IAM --> POLICY
              |__> TRUST RELATIONSHIP.

1-Created Table
2-
AWS Region->us-east-1
AWS service->DynamoDB
AWS subdomain->blank
HTTP method->POST
Action type
Use action name(tick) - X Use path override Xnotick

Action name -> PutItem
Execution role
arn:aws:iam::767665886117:role/DynamoDB_API_PutItem


3-
DynamoDBFullAccess
Trust:
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "APIgateway",
			"Effect": "Allow",
			"Principal": {
				"Service": "apigateway.amazonaws.com"
			},
			"Action": "sts:AssumeRole"
		}
	]
}

create resource->method->deploy
postman-> test
body->raw 
{
    "TableName": "customers",
    "Item": {
        "customerId": {
            "S": "1"
        },
        "date": {
            "S": "2023"
        },
        "name": {
            "S": "azamsajjad"
        }
    }
}

BUT THIS IS INCSECURE

INSTEAD, CREATE A MAPPING TEMPLATE 
/ -> customers -> POST -> Create MApping Template 

{
    "TableName": "customers",
    "Item": {
        "customerId": {
            "S": "$context.requestId"
        },
        "date": {
            "S": "$input.path('$.date')"
        },
        "name": {
            "S": "$input.path('$.name')"
        }
    }
}

New Cleaner Input required now---
{
        "date": "2023"
        "name": "azam sajjad"
}
// for customerid, $context.requestId generates a random customer id 16 digit unique
===========================================================================
Lambda authorizers
–
An API Gateway Lambda authorizer invokes a Lambda function to authenticate/validate a user against your existing IdP. This type of authorizer is useful for centralized authentication.
TYPES:
TOKEN-BASED LAMBDA AUTHORIZERS.
REQUEST AUTHORIZER.

you can also use cross-account lambda authorizer. 
authorizer in one account, 
===========================================================================
Managing ACCESS to APIs

The next important step for you to consider after you have successfully designed and deployed your API is how you will manage access and authorization for the API. API Gateway provides you with multiple, customizable options for:

Authorizing an entity to access your APIs
Providing more granular control
Controlling the amount of access through throttling
Before discussing these different use cases, you need to understand the different options for authenticating and authorizing your APIs in API Gateway.


TYPES:                          Authentication | Authorization | Signature V4| Cognito User Pools | 3rdParty Auth
Aws Iam-------------------------------y-----------------y-------------y------------------------------------------
Lambda Authorizer Token---------------y-----------------y------------------------------y-----------------y-------
Lambda Authorizer Request-------------y-----------------y------------------------------y-----------------y-------
Amazon Cognito------------------------y-----------------y------------------------------y-------------------------
===========================================================================
Aws Iam------------------------------None
Lambda Authorizer Token--------------Pay per authorizer invoke
Lambda Authorizer Request------------Pay per authorizer invoke----------------------Multiple Header Support
Amazon Cognito-----------------------Pay based on your monthly active users

As shown in the comparison table, there are three main ways to authorize API calls to your API Gateway endpoints:

1

1
Use IAM and Signature version 4 (also known as Sig v4) to authenticate and authorize entities to access your APIs.

2

2
Use Lambda Authorizers, which you can use to support bearer token authentication strategies such as OAuth or SAML.

3

3
Use Amazon Cognito with user pools.


Authorizing with IAM
If you have an internal service or a restricted number of customers, IAM is a great choice for
authorization, especially for applications that use IAM to interact with other AWS services using IAM roles. 

Lambda Authorizers
You also need to consider what you already have in place that should be used. If you are using an OAuth strategy as an organization, you may want to consider Lambda Authorizer. 
To make it easy to get started with this method, you can choose the API Gateway Lambda Authorizer blueprint when creating your authorizer function from the Lambda console.

Lambda function console creation using API Gateway Lambda Authorizer blueprint to create the Lambda Authorizer.
To summarize, a Lambda Authorizer is simply a Lambda function that you can write to perform any custom authorization that you need. There are two types of Lambda Authorizers you should be aware of: Token and Request.

For token-type Lambda Authorizers, API Gateway passes the source token to the Lambda function as a JSON input. Based on the value of this token, your Lambda function will determine whether to allow the request. 
Request-type Lambda Authorizers are useful if you need more information about the request itself before authorizing it.

IAM Authorizer          All requests are required to be signed using AWS Sig v4.
Lambda Authorizer       Amazon API Gateway supplies an authorization token to a Lambda function.
Cognito Authorizer      After a user is authenticated against the user pool, they obtain an OIDC token.

--------------------------------------------------------------------------------------------------------
Throttling and usage plans

Beyond just allowing or denying access to your APIs, API Gateway also helps you manage the volume of API calls that are processed through your API endpoint. 

With API Gateway, you can set throttle and quota limits on your API consumers. This can useful for things such as preventing one consumer from using all of your backend system’s capacity or to ensure that your downstream systems can manage the number of requests you send through. 

Keys on a key ring
API keys

        With API Gateway, you can create and distribute API keys to your customers, which can be used to identify the consumer and apply desired usage and throttle limits to their requests. Customers include the API key through x-API-key header in requests. 

Usage plans

        You can use API keys with usage plans to set up some very specific plans that make sense for your use case. For example, you can perform API key throttling based on a rate and a burst per API key. API key usage can also be used to meter daily, weekly, and monthly usage. 

You can set throttle and quota limits based on API keys through the usage plans feature. You can set up usage plans for:

API Key Throttling per second and burst
API Key Quota by day, week, or month
API Key Usage by daily usage records


Token Bucket Algorithm----------

Burst: Maximum size of bucket
Rate: Number of tokens (requests) added to bucket
The method by which the limits are measured and throttled is based on the token bucket algorithm, which is a widely used algorithm for checking that network traffic conforms to set limits. A token, in this case, counts as a request and the burst is the maximum bucket size.

Requests that come into the bucket are fulfilled at a steady rate. If the rate at which the bucket is being filled causes the bucket to fill up and exceed the burst value, a 429 Too Many Requests error would be returned.

API Gateway sets a limit on a steady-state rate and a burst of request submissions per account and per Region. At the account level, by default, API Gateway limits the steady-state request rate to 10,000 requests per second. It limits the burst to 5,000 requests across all APIs within an AWS account. However, as discussed earlier, you can use usage plans to manage limits at a more granular level.

Throttling Settings Hierarchy----------

The type and level of throttling applied to a request is dependent on all of the limits involved and are applied in this order:

1-Per-client, per-method throttling limits that you set for an API stage in a usage plan
2-Per-client throttling limits that you set in a usage plan
3-Default per-method limits and individual per-method limits that you set in API stage settings
4-The account level limit
=====================================================================
IAM permissions

You learned how IAM policies are used as part of the authorization models as an earlier part of this lesson. Now, it's time to take a look at the types of permission controls you can implement using IAM policies. There are two types of IAM permissions for APIs:'

Who can invoke the API                          Who can manage the API
execute-api:*                                   apigateway:*
"Action": {                                     "Action": {
    execute-api: Invoke                             apigateway: GET
Who can invoke the API: To call a deployed API, or refresh the API caching, the caller needs the execute-api permission.
// When you do this, API Gateway will expect an IAM Sig v4 request for any requests that come to that API method. After you have associated this authorization type with your API method, you can then allow users with this permission to invoke your API. This could be an IAM user who represents an API caller; it could be an IAM group containing a set of IAM users; or it could be an IAM role assumed by a user, an EC2 instance, or an application running inside AWS. 

Who can manage the API: To create, deploy, and manage an API in API Gateway, the API developer needs the apigateway permission.


-------------------------------------------Resource Policies------------------------------------------------------

Resource policies help you to further refine access for your APIs. While an IAM policy is used to grant permission to a user, group, or role, you can also apply policies directly on API Gateway using a resource policy. A resource policy is a JSON policy document that you attach to an API to limit access by users from a specified account, IP address range, VPC, or VPC endpoint. You can make this as granular as you need, and resource policies can be used in coordination with IAM policies to restrict access. 

For example, you could use resource policies to provide access to another AWS account, or to limit access to your API from a particular set of IP address ranges. You can also use resource policies to grant access to specific VPCs or VPC endpoints.

"Principal": {
    "AWS":
        "arn:aws:iam::user/George
OR

"Effect": "Deny",
"Principal": {
"Action": "execute—api: Invoke" ,
"Resource": {
"arn:aws:execute-api:region:account-id:api-id/ *"
Condition"
"IpAddress": {
        "aws:Sourcelp" :["192.0.2.0/24", "198.51.100.0/24"
OR
'Condition' {
"StringNotEquals": {
    "aws:SourceVpc": "vpc—la2b3c4d"






----------------------------------Resource Policies and Authentication Methods------------------------------------

Resource policy and authentication methods work together to grant access to your APIs. As illustrated below, methods for securing your APIs work in aggregate. To learn more, expand each of the following four categories.


API Gateway resource policy only
–
Explicit allow is required on the inbound criteria of the caller. If not found, deny the caller. 

Lambda Authorizer and resource policy
–
If the policy has explicit denials, the caller is denied access immediately. 
Otherwise, the Lambda Authorizer is called and returns a policy document that is evaluated with the resource policy. 

IAM authentication and resource policy
–
If the user authenticates successfully with IAM, policies attached to the IAM user and resource policy are evaluated together. 
If the caller and API owner are from separate accounts, both the IAM user policies and the resource policy explicitly allow the caller to proceed.
If the caller and the API owner are in the same account, either user policies or the resource policy must explicitly allow the caller to proceed.

Cognito authentication and resource policy
–
If API Gateway authenticates the caller from Cognito, the resource policy is evaluated independently.
If there is an explicit allow, the caller proceeds.
Otherwise, deny or neither allow nor deny will result in a deny.
=====================================================================
Monitoring and Troubleshooting
CloudWatch Metrics for API Gateway

After your APIs are deployed, you can use CloudWatch Metrics to monitor performance of deployed APIs. API Gateway has seven default metrics out of the box:

1
Count: Total number of API requests in a period
2
Latency: Time between when API Gateway receives a request from a client and when it returns a response to the client; this includes the integration latency and other API Gateway overhead
3
IntegrationLatency: Time between when API Gateway relays a request to the backend and when it receives a response from the backend
4
4xxError: Client-side errors captured in a specified period
5
5xxError: Server-side errors captured in a specified period
6
CacheHitCount: Number of requests served from the API cache in a given period
7
CacheMissCount: Number of requests served from the backend in a given period, when API caching is turned on
Calculating API Gateway overhead

API Gateway Overhead------------------------------------------------

Two Key Metrics that are used to calculate the API Gateway overhead of deployed APIs are the Latency and IntegrationLatency CloudWatch Metrics.
1
The latency metric gives you details about how long it takes for a full round-trip response, from the second your customer invokes your API to when your API responds with the results. This is a full round-trip duration of an API request through API Gateway.
2
Integration latency is how long it takes for API Gateway to make the invocation to your backend and receive the response.

The difference between these two metrics gives you your API Gateway overhead. Together, these metrics can help you fine-tune your applications and see where the bottlenecks are.

CloudWatch Logs for API Gateway--------------------------------------

In addition to CloudWatch Metrics, you can also learn a lot about how your APIs are performing from CloudWatch Logs. API Gateway has two types of CloudWatch logs built in. 

ECECUTION LOGGING -(Costly, Reveals Sensitive Info, Not Recommended for Prod)
The first type is execution logging, which logs what’s happening on the roundtrip of a request. You can see all the details from when the request was made, the other request parameters, everything that happened between the requests, and what happened when API Gateway returned the results to the client that’s calling the service.

Execution logs can be useful to troubleshoot APIs, but can result in logging sensitive data. Because of this, it is recommended you dont enable Log full requests/responses data for production APIs. In addition, there is a cost component associated with logging your APIs.

ACCESS LOGGING
The second type is access logging, which provides details about who's invoking your API. This includes everything including IP address, the method used, the user protocol, and the agent that's invoking your API. 
Monitoring with X-Ray and CloudTrail



There are two AWS tools you should understand to analyze your API use and performance: AWS X-Ray and AWS CloudTrail.

AWS X-Ray-----------------------------------------------------------

You can use X-Ray to trace and analyze user requests as they travel through your Amazon API Gateway APIs to the underlying services. With X-Ray, you can understand how your application is performing to identify and troubleshoot the root cause of performance issues and errors. X-Ray gives you an end-to-end view of an entire request, so you can analyze latencies and errors in your APIs and their backend services. You can also configure sampling rules to tell X-Ray which requests to record, and at what sampling rates, according to criteria that you specify.

To summarize, with X-Ray, you can trace and analyze requests as they travel through your APIs to services:

Analyze latencies and debug errors in your APIs and their backend services.
Configure sampling rules to focus on specific requests.

AWS CloudTrail--------------------------------------------------------

The second service, CloudTrail, captures all API calls for API Gateway as events, including calls from the API Gateway console and from code calls to your API Gateway APIs. 
Using the information collected by CloudTrail, you can determine the request that was made to API Gateway, the IP address from which the request was made, who made the request, when it was made, and additional details. You can view the most recent events in the CloudTrail console in Event history.

To summarize, CloudTrail captures all API calls for API Gateway as events.

IP address, requester, and time of request are included.
Event history can be reviewed.
Create a trail to send events to an Amazon Simple Storage Service (Amazon S3) bucket.
=====================================================================
You have three separate environments in your AWS account and three corresponding stages in the API Gateway. You are using the API Gateway as a HTTP proxy to a backend endpoint. How do you direct traffic for each environment without creating separate API Gateways?


Use a request transformation to transform the backend endpoint responses.


Use custom authorizers for each stage.

'
Use stage variables and configure the stage variables in the HTTP integration request to interact with different backend endpoints.'
You can use API Gateway stage variables to access the HTTP and Lambda backends for different API deployment stages.

Update the integration response to update the backend endpoints.

=====================================================================
You are building a web application that uses API Gateway to expose a Lambda function to process requests from clients over the internet. While testing, the API Gateway frequently times out; however, when calling the Lambda function directly, it completes successfully every time.

Which of the following API Gateway metrics in Amazon CloudWatch should you check in order to troubleshoot the issue?

Count

CacheMissCount

CacheMissCount relates to the number of requests served from the backend in a given period, when API caching is enabled. A cache miss should not cause API Gateway to time out, so this metric will not help you to understand why the API is timing out.

Reference: API Gateway metrics

Selected
Latency`````````````````````````````````````

Latency relates to the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. This is useful because a latency issue could be causing the timeout.

Reference: API Gateway metrics

Selected
IntegrationLatency````````````````````````````

IntegrationLatency relates to the time between when API Gateway relays a request to the backend and when it receives a response from the backend. This is useful because a latency issue could be causing the timeout.


---------------------------------------------------------------------------------------------------------
You are developing an application in API Gateway and need to categorize your APIs based on their status as: sandbox, test, or prod. You want to use a name-value pair system to define configuration attributes associated with deployment stages of your APIs, and use it in your API setup and mapping templates. What feature of API Gateway would you use to accomplish this task?


Use stage variables based on the API deployment stage to interact with different backend endpoints.``````


Use environment variables based on the API deployment stage to interact with different backend endpoints.


Use tags based on stages. The tag can be set directly on the stage of the API.


Use the API Gateway console to create a canary release deployment.
---------------------------------------------------------------------------------------------------------
You are a developer working on a brand new serverless application that teaches the world to cloud. You have performed your initial deployment using Lambda and API Gateway and would like to work toward adding API Gateway stages and associate them with your prod, dev, and test environments. Your stages will need to match a Lambda function variant that is different for each of the environments, allowing you to test across different stages of the software lifecycle. Which of the following features must you add to achieve this?

Lambda layers

Lambda aliases````````````````

A Lambda alias is like a pointer to a specific function version. Users can access the function version using the alias Amazon Resource Name (ARN).

Selected
Lambda versions

Lambda versions are used to manage the deployment of your functions. For example, you can publish a new version of a function for beta testing without affecting users of the stable production version. Lambda creates a new version of your function each time that you publish the function. A version can be used to create an alias but cannot be referenced using a stage variable. In order to have API Gateway reference a specific variant of a function, it needs to use an alias.

Selected
Stage variables```````````````````

With deployment stages in API Gateway, you can manage multiple release stages for each API, such as dev, test, and production. Using stage variables, you can configure an API deployment stage to interact with different backend endpoints. Reference: API Gateway Stage Variables




---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------

Which of these migrations patterns helps an organization incrementally and systematically decomposes monolithic applications by creating APIs and building event-driven components that gradually replace components of the legacy application?

Leapfrog

Correctly unselected
Strangler

Correctly selected
Organic

Correctly unselected
Saga

Correctly unselected
Correct
With the strangler pattern, an organization incrementally and systematically decomposes monolithic applications by creating APIs and building event-driven components that gradually replace components of the legacy application.



Distinct API endpoints can point to old vs. new components, and safe deployment options (like canary deployments) let you point back to the legacy version with very little risk.



To learn more about different migration patterns, review the Migrating to Serverless lesson.
---------------------------------------------------------------------------------------------------------
You are trying to diagnose a performance problem with your serverless application, which uses Lambda, API Gateway, S3, and DynamoDB. Your DynamoDB table is performing well, and you suspect that your Lambda function is taking too long to execute. Which of the following could you use to investigate the source of the issue?

Lambda invocations sum metric in CloudWatchXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX   WRONG

    Lambda invocations sum measures the number of times a function is invoked in response to an event or invocation API call.

AWS X-Ray```````````````````````

    AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway integration latency is the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda invocations sum measures the number of times a function is invoked in response to an event or invocation API call.

API Gateway integration latency metric in CloudWatch``````````````````````````

    AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway integration latency is the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda invocations sum measures the number of times a function is invoked in response to an event or invocation API call.

API Gateway latency metric in CloudWatch
---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------


API Gateway integration latency is the time between when API Gateway relays a request to the backend and when it receives a response from the backend.

API Gateway latency is the time between when API Gateway receives a request from a client and when it returns a response to the client.

---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------


A company hosts its web application backend on Amazon Elastic Container Service (Amazon ECS). The application's Amazon ECS tasks run behind an Application Load Balancer (ALB). The application supports three environments: production, testing, and development. The application uses the ALB to route traffic to the correct environment.

The company has configured three listener rules for the ALB to forward traffic to a different target group based on the port number (Port 80 for production target group, Port 8080 for testing target group, and Port 8081 for development target group).

The company decides to migrate the application backend to a serverless architecture by using an Amazon API Gateway API backed by AWS Lambda functions. The company plans to use the URI path pattern to access the desired environment instead of the port number. The company has created the Lambda functions for the application backend. Each Lambda function has three aliases (production, testing, and development).

Which option includes the next steps the company must take to complete the process?

A```````````````````````
Create an API Gateway API and configure the routes to use Lambda proxy integration. Target the corresponding Lambda function Amazon Resource Name (ARN) that is concatenated with the expression ${stageVariables.LambdaAlias}. Modify the Lambda resource-based policy by adding the permission lambda:InvokeFunction. Create production, testing, and development stages. Add the LambdaAlias stage variable to the corresponding stage.

Correct. To add "stageVariable" to the Lambda ARN, you should use the following format: ${stageVariable.stageVariableName}.

For more information about API Gateway stage variables, see Using Amazon API Gateway Stage Variables.


B
Create an API Gateway API and configure the routes to use Lambda proxy integration. Target the corresponding Lambda function Amazon Resource Name (ARN) that is concatenated with the name of the Lambda alias. Modify the Lambda resource-based policy by adding the permission lambda:InvokeFunction. Create production, testing, and development stages. Add the LambdaAlias stage variable to the corresponding stage.
Incorrect. To add "stageVariable" to the Lambda ARN, you do not use the Lambda alias name. You should use the following format: ${stageVariable.stageVariableName}.


C
Create an API Gateway API and configure the routes to use Lambda proxy integration. Target the corresponding Lambda function Amazon Resource Name (ARN) that is concatenated with the expression ${stageVariables.LambdaAlias}. Modify the Lambda execution role by adding the permission apigateway:*. Create production, testing, and development stages. Add the LambdaAlias stage variable to the corresponding stage.
Incorrect. You use the Lambda execution role to grant Lambda permission to AWS resources. The resource-based policy allows other services to invoke the Lambda function.

For more information about Lambda and AWS Identity and Access Management (IAM), see AWS Lambda Permissions.


D
Create an API Gateway API and configure the routes with Lambda proxy integration. Target the corresponding Lambda function Amazon Resource Name (ARN) that is concatenated with the name of the Lambda alias. Modify the Lambda execution role by adding the permission apigateway:*. Create production, testing, and development stages. Add the LambdaAlias stage variable to the corresponding stage.
Incorrect. To add "stageVariable" to the Lambda ARN, you do not use the Lambda alias name. You should use the following format: ${stageVariable.stageVariableName}. You use the Lambda execution role to grant Lambda permission to AWS resources. The resource-based policy allows other services to invoke the Lambda function.


===============================================================================================================
'
A company has a microservices application that must be integrated with API Gateway. The developer must configure custom data mapping between the API Gateway and the microservices.

In addition, the developer must specify how the incoming request data is mapped to the integration request and how the resulting integration response data is mapped to the method response.

Which of the following integration types is the MOST suitable one to use in API Gateway to meet this requirement?


HTTP_PROXY

HTTP```````````````

AWS_PROXY

AWS

You can integrate an API method in your API Gateway with a custom HTTP endpoint of your application in two ways:

 – HTTP proxy integration

 – HTTP custom integration

In your API Gateway console, you can define the type of HTTP integration of your resource by toggling the “Configure as proxy resource” checkbox.

With proxy integration, the setup is simple. You only need to set the HTTP method and the HTTP endpoint URI, according to the backend requirements, if you are not concerned with content encoding or caching.

With custom integration, setup is more involved. In addition to the proxy integration setup steps, you need to specify how the incoming request data is mapped to the integration request and how the resulting integration response data is mapped to the method response. API Gateway supports the following endpoint ports: 80, 443 and 1024-65535.

Programmatically, you choose an integration type by setting the type property on the Integration resource. For the Lambda proxy integration, the value is AWS_PROXY. For the Lambda custom integration and all other AWS integrations, it is AWS. For the HTTP proxy integration and HTTP integration, the value is HTTP_PROXY and HTTP, respectively. For the mock integration, the type value is MOCK.

Since the integration type that is being described in the scenario fits the definition of an HTTP custom integration, the correct answer in this scenario is to use the HTTP integration type.

AWS is incorrect because this type is only used for Lambda custom integration. Take note that the scenario uses an application hosted in EC2 and not in Lambda.

AWS_PROXY is incorrect because this type is primarily used for Lambda proxy integration. The scenario didn’t mention that it uses a serverless application or Lambda.

HTTP_PROXY is incorrect because this type is only used for HTTP proxy integration where you don’t need to do data mapping for your request and response data.

=========================================================================================================

With proxy integration, the setup is simple. You only need to set the HTTP method and the HTTP endpoint URI, according to the backend requirements, if you are not concerned with content encoding or caching.

With custom integration, setup is more involved. In addition to the proxy integration setup steps, you need to specify how the incoming request data is mapped to the integration request and how the resulting integration response data is mapped to the method response. API Gateway supports the following endpoint ports: 80, 443 and 1024-65535.

Programmatically, you choose an integration type by setting the type property on the Integration resource. For the Lambda proxy integration, the value is AWS_PROXY. For the Lambda custom integration and all other AWS integrations, it is AWS. For the HTTP proxy integration and HTTP integration, the value is HTTP_PROXY and HTTP, respectively. For the mock integration, the type value is MOCK.

Since the integration type that is being described in the scenario fits the definition of an HTTP proxy integration, the correct answer in this scenario is to use the HTTP_PROXY integration type.

=========================================================================================================
A developer is using API Gateway Lambda Authorizer to provide authentication for every API request and control access to your API. The requirement is to implement an authentication strategy which is similar to OAuth or SAML.

Which of the following is the MOST suitable method that the developer should use in this scenario?

Cross-Account Lambda Authorizer
Token-based Authorization`````````````````````````
AWS STS-based Authentication
Request Parameter-based Authorization



Incorrect
A Lambda authorizer is an API Gateway feature that uses a Lambda function to control access to your API. When a client makes a request to one of your API’s methods, API Gateway calls your Lambda authorizer, which takes the caller’s identity as input and returns an IAM policy as output.

There are two types of Lambda authorizers:

 – A token-based Lambda authorizer (also called a TOKEN authorizer) receives the caller’s identity in a bearer token, such as a JSON Web Token (JWT) or an OAuth token.

 – A request parameter-based Lambda authorizer (also called a REQUEST authorizer) receives the caller’s identity in a combination of headers, query string parameters, stageVariables, and $context variables.


 ===============================================================================================================
 A serverless application consisting of Lambda functions integrated with API Gateway, and DynamoDB processes ad hoc requests that its users send. Due to the recent spike in incoming traffic, some of your customers are complaining that they are getting HTTP 504 errors from time to time.

Which of the following is the MOST likely cause of this issue?

An authorization failure occurred between API Gateway and the Lambda function.
Since the incoming requests are increasing, the API Gateway automatically enabled throttling which caused the HTTP 504 errors.
"API Gateway request has timed out because the underlying Lambda function has been running for more than 29 seconds."
The usage plan quota has been exceeded for the Lambda function.
Correct
A gateway response is identified by a response type defined by API Gateway. The response consists of an HTTP status code, a set of additional headers that are specified by parameter mappings, and a payload that is generated by a non-VTL (Apache Velocity Template Language) mapping template.




You can set up a gateway response for a supported response type at the API level. Whenever API Gateway returns a response of the type, the header mappings and payload mapping templates defined in the gateway response are applied to return the mapped results to the API caller.

The following are the Gateway response types which are associated with the HTTP 504 error in API Gateway:

INTEGRATION_FAILURE – The gateway response for an integration failed error. If the response type is unspecified, this response defaults to the DEFAULT_5XX type.

INTEGRATION_TIMEOUT – The gateway response for an integration timed out error. If the response type is unspecified, this response defaults to the DEFAULT_5XX type.

"For the integration timeout, the range is from 50 milliseconds to 29 seconds for all integration types, including Lambda, Lambda proxy, HTTP, HTTP proxy, and AWS integrations."

In this scenario, there is an issue where the users are getting HTTP 504 errors in the serverless application. This means the Lambda function is working fine at times but there are instances when it throws an error. Based on this analysis, the most likely cause of the issue is the INTEGRATION_TIMEOUT error since you will only get an INTEGRATION_FAILURE error if your AWS Lambda integration does not work at all in the first place.

Hence, the root cause of this issue is that the API Gateway request has timed out because the underlying Lambda function has been running for more than 29 seconds.

The option that says: Since the incoming requests are increasing, the API Gateway automatically enabled throttling which caused the HTTP 504 errors is incorrect because a large number of incoming requests will most likely produce an HTTP 502 or 429 error but not a 504 error. If executing the function would cause you to exceed a concurrency limit at either the account level (ConcurrentInvocationLimitExceeded) or function level (ReservedFunctionConcurrentInvocationLimitExceeded), Lambda may return a TooManyRequestsException as a response. For functions with a long timeout, your client might be disconnected during synchronous invocation while it waits for a response and returns an HTTP 504 error.

The option that says: An authorization failure occurred between API Gateway and the Lambda function is incorrect because an authentication issue usually produces HTTP 403 errors and not 504s. The gateway response for authorization failures for missing authentication token error, invalid AWS signature error, or Amazon Cognito authentication problems is HTTP 403, which is why this option is unlikely to be the cause of this issue.

The option that says: The usage plan quota has been exceeded for the Lambda function is incorrect. Although this is a possible root cause for this scenario, this option has the least chance to produce HTTP 504 errors. The scenario says that the issue happens from time to time and not all the time which suggests that this happens intermittently. If the usage plan indeed exceeded the quota, then the 504 error should always show up and not just from time to time.