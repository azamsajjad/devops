Amazon Redshift

Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. A Redshift data warehouse is a collection of computing resources called nodes, which are organized into a group called a cluster. Each cluster runs an Amazon Redshift engine and contains one or more databases.

Amazon Redshift databases are designed as analytical repositories. They can store aggregate values from transactional databases and dozens of other source locations.

Amazon Redshift can achieve its massive speed improvements by implementing columnar indexing of the data and parallel processing. 

With Amazon Redshift Spectrum, you can query data within an Amazon S3 bucket or data lake without having to move the data into the Amazon Redshift cluster.
Amazon Redshift Spectrum and Concurrency Scaling are optional features of Amazon Redshift that you will be billed for if enabled.

You can encrypt data using keys you manage through AWS KMS. Connections to the database are secured using HTTPS. IAM is used to authorize and authenticate users to Amazon Redshift clusters.

Remember I mentioned that Amazon Redshift is different from relational databases because it stores analytical data? One of the advantages of Amazon Redshift is that it uses a massively-parallel, columnar architecture. That means that data is indexed in a way that matches the way analytical queries are written.

So how does Amazon Redshift work? Well, internally Amazon Redshift is broken down into nodes. There is a single leader node and several compute nodes. Clients access Amazon Redshift via a SQL endpoint on the leader node. The client sends a query to the endpoint.

Amazon Redshift clusters are comprised of nodes. Compute nodes divide work among slices. Each slice is assigned a portion of the node’s memory and drive space. When you connect to an Amazon Redshift cluster, you use the SQL endpoint.

The leader node creates jobs based on the query logic and sends them in parallel to the compute nodes. The compute nodes contain the actual data the queries need. The compute nodes find the required data, perform operations, and return results to the leader node. The leader node then aggregates the results from all of the compute nodes and sends a report back to the client.

So now let’s discuss a couple ways you can use Amazon Redshift data warehouses.

You can use Amazon Redshift to build a unified data platform. Creating multiple copies of data is a huge waste of time and money; however, traditional data warehousing required that all data be loaded into the data warehouse. Amazon Redshift Spectrum can run queries across your data warehouse and Amazon S3 buckets simultaneously. You save time and money by leaving data where it is.

A popular mobile manufacturing company was struggling with sluggish query results. The company benefited from migrating their on-premises data warehouse to Amazon Redshift. After the migration, they were able to run queries twice as fast and were able to mine and analyze massive volumes of data at 50 percent of the cost.


==========================================================================
PRICING 
There are four pricing types.

On-Demand pricing has no upfront costs. You simply pay an hourly rate based on the type and number of nodes in your cluster.

With Concurrency Scaling pricing, you simply pay a per-second on-demand rate for usage that exceeds the free daily credits. Each cluster earns up to one hour of free Concurrency Scaling credits per day, which is sufficient for most customers.

Reserved Instance pricing enables you to save up to 75 percent over On-Demand rates by committing to using Amazon Redshift for a 1- or 3-year term.

Amazon Redshift Spectrum pricing is applied when you begin using this feature. In addition to the cluster pricing, you pay for the number of bytes scanned on Amazon S3.


There is no charge for data transferred between Amazon Redshift and Amazon S3 within the same AWS Region for backup, restore, load, and unload operations. For all other data transfers, you are billed using the standard AWS data transfer rates.

==================================
CONNECTION
So, how do you connect to an Amazon Redshift cluster? By using an endpoint. An endpoint is a URL that contains a host address and a port. Use the SQL endpoint to connect your application to Amazon Redshift. You can use any application that uses an industry standard JDBC or ODBC driver for PostgreSQL.
===================================
ARCHITECTURE 
In this architecture, you see one way to build a rich data platform by combining data from multiple data sources. AWS Glue can combine transactional data from an Amazon RDS database with archived records from an Amazon Simple Storage Service (Amazon S3) bucket. Once this data has been combined and transformed, it can then be loaded into an Amazon Redshift data warehouse.
"
Transactional Data -RDS------
                            |-> Transform  -> Analytical Data
Archive Data -S3-----------/^    -AWS Glue      Redshift
"

In another architecture, you can build out an event-driven data analysis platform by using Amazon Kinesis Data Firehose to gather data from on-premises data servers. Kinesis Data Firehose can trigger an AWS Lambda function that loads the data into an Amazon S3 data lake. The Amazon Redshift cluster can now query not only the data within the data warehouse but also the data in the data lake using Amazon Redshift Spectrum. You can then visualize this data with Amazon QuickSight.


"                                              Analyze
customer     firehose          data lake    AWS Redshift      Visualize
db sources -> kinesis -> Lambda -> S3 -> Redshift Spectrum ->aws Quicksight
"


Rich data platform architecture

Amazon Redshift is a perfect repository for analytical data. The question becomes how to get quality data into the database with speed, efficiency, and accuracy. This is one architecture for building out a rich data platform pulling data from multiple data sources.

