Lambda Charges: (pay only when your code executes)
1 - Based on Requests
first million requests per month are free 
$0.20 per month per 1 million requests 

2- Duration 
You are charged in millisecond increments 
price depend on amount of memory you allocate to your lambda function 
Price per GB-Second 
$0.00001667 per GB-Second 
A function that uses 512mb and runs for 100ms 
0.5GB x 0.1s = 0.05 GB-Seconds 
cost = $0.0000000083 
First 400,000 GB-Seconds per month are free

Lambda is Event-driven 
Lambda is Independent - each event will trigger a single function
Lambda is triggered by Events e.g. changes to s3 bucket/DB run function
Lambda is also triggered User Request e.g. alexa

LAMBDA TRIGGERS: (aws services)
DynamoDB
Kinesis 
SQS 
Application Load Balancer 
API Gateway 
Alexa 
CloudFront 
S3
SNS 
SES 
CloudFormation 
CloudWatch 
CodeCommit 
CodePipeline


API : Application Programming Interface 
we use APIs to interact with web applications 
Applications use APIs to communicate with each other

API GATEWAY : is serverless, supports throttling, logged to CloudWatch
API GATEWAY provides endpoints for your apps running in aws
publish maintain and monitor APIs 
API TYPES :
RESTful APIs are optimized for stateless, serverless workloads
REST=REpresentational State Transfer, supports JSON
Websocket APIs are for real-time, two-way, stateful communication e.g. chat apps
users -> API GATEWAY -> Lambda
users -> API GATEWAY -> EC2
users -> API GATEWAY -> DynamoDB

$LATEST is the latest version of code you uploaded into lambda 
how to version control 
upload code > action > publish new version > create alias 
(weighted traffic routing also supported between versions)

Concurrent Execution Limit is 1000 functions per region per account
HTTP status code 429
you can also reserve some concurrency for critical lambda functions
they will be prioritized
but it also sets limit for that function.e.g if you reserve 500 simultaneous function execution for a particular function, it will never go beyond 500 concurrent runs

LAMBDA and VPC Access 
it is possible to enabe lambda access resources that are inside private VPC
these resources can be EC2/RDS/etc
Lambda creates ENIs using IP from private subnets
configuration > permissions > Execution role url
AWSLambdaVPCAccessExecutionRole (add this policy for lambda to access VPC)


---------------------------------------------------------------------------
Severless Architectures are Event-Driven and Asynchronous
->so an event may trigger an action, but no response is required/expected
SQS allows you to queue messages
EventBridge helps to handle events & route them to application components
Characteristics of Event-Driven Architecture 
        Event Source    --> Event Router -->    Event Destination
            s3              EventBridge         Lambda
            dynamoDB                            SNS
                                                Lambda
---------------------------------------------------------------------------
STEP Functions: 
provide visual interfac for serverless apps app is series of steps excuted in order as defined by your business logic
Output of one step can be input of next step
step functions also logs state of each step

STEP Functions Workflows
Standard Workflows: 
     -> Long-Running (upto 1 yar)
     -> At-Most-Once Model  - (tasks are never executed more than once, unless explicitly specified by retry actions.)
     -> Non-Idempotent Actions e.g. when processing payments, you want payment to be processed once
     -> Change in State? a req is non-idempotent if it always change state

Express Workflows:
    -> Short-Lived (upto 5 minutes)
    -> At-Least-Once 
    -> Idempotent Actions
    -> Identical Request - has no side effect
    2 types of Express Workflows
        -> Synchronous - begins workflow->wait till complete->return result
            workflows hold u up until they are complete
            e.g. job interview, successful payment b4 processing order
        -> Asynchronous - begins->confirm that its started->cloudwatch logs
            runs in the background
            e.g. email to a colleage, messaging system

---------------------------------------------------------------------------
LAMBDA STORAGE PATTERNS:

Lambda is stateless (you cannot permanently store any data in the function)
Lambda is Ephemeral (not used for apps that need to run 4longer than 15min)
To make Lambda Persistent -> make it interact with a data store.
                            e.g. S3,EFS,DynamoDB or /tmp,layers

/tmp , lambda layers = Native Lambda storage options
/tmp = by default 512mb, configurable upto 10GB (but NON_PERSISTENT)
/tmp = used while function is executing
/tmp = like a cached file system
/tmp = shared within execution environments

Storing Lambda Libraries - can be included with the code as zip file 
LAYERS                     but it makes deployment heavy
LAYERS = limit 50mb zipped, 250mb unzipped
LAYERS = shared across execution environments
- Best Practice (Add libraries & SDKs as layers)
    (However, if you want to change version of a library included)
    (you can''t update it dynamically)
    (you need to create a new layer & reference that)

PERSISTENT_STORAGE:
S3  -> elastic, means no size limit
    -> but there are constraints, because S3 is object storage 
    -> allows you to store & retrieve objects, not a file system 
    -> Cannot Append data 
    -> if you want to change data, you need to upload a new object
better option = EFS ~ Shared file system 
EFS = dynamically updated, no size limit
    = mounted by the function when execution environment is created 
    = can be shared across invocations 
    = VPC-to use EFS, lambda function must be in same VPC as EFS file system

---------------------------------------------------------------------------
LAMBDA ENVIRONMENT VARIABLES 
-> adjust your function behavior, without changing your code
-> make your function behave differently in dev env. than it does in prod.
-> key-value pairs (key=environment, value=development)
ENV Variables are locked once the Version is published 
ENV Variables are defined before Version is published
USE-CASES = references S3 resources, SNS Topic, DynamoDB Table
             BUCKET=my-bucket  SNSTOPIC=my-Topic  TABLE=my-table

---------------------------------------------------------------------------
LAMBDA INVOCATIONS 
when invoking a function, you can invoke it synchronously or asynchronously
SYNC Invocation -> lambda runs the function, wait for its response, returns the response
                -> the service calling the function will know if the function completed successfully or not
                -> e.g. API Gateway invoking a function and returning error code to the caller
ASYNC Invocation -> No Acknowledgement to let you know invocation was successful
                -> the service calling the function will not know if the function completed successfully or not
LAMBDA Retries:
default -> performs 2 retries 
lambda waits 1 min before first retry, it waits 2 minutes before 2nd retry

[DLQs and Destinations]

Dead-Letter Queues (DLQs):
save failed invocations for further processing 
associated with a particular version of a function 
can be an event source for a function, allowing you to re-process events.
handles failures only 
SQS->holds failed events in the queue until they are retrieved 
SNS->send notification about failed events to one or more destinations

Lambda Destinations: optionally, configure lambda to send invocation records to another service 
lambda --invocation_success-->EventBridge-->so successful inv are tracked
lambda --invocation_success-->SQS-->queue for review
lambda --invocation_failure-->SNS-->mail or sms
lambda --invocation_failure-->lambda-->trigger another function

LAB
create function 
create SNS topic -> add subscription -> add email
configuration -> destinations -> ASYNC & Condition & Destination Type
$ aws lambda invoke --function-name myfunction --invocation-type Event response.json
you will receive an email from SNS
// {"version":"1.0","timestamp":"2023-08-15T19:56:55.223Z","requestContext":{"requestId":"0d2b2356-82c9-4380-8fbf-ef268102c8e4","functionArn":"arn:aws:lambda:us-east-1:145794000460:function:myFunction1:$LATEST","condition":"Success","approximateInvokeCount":1},"requestPayload":{},"responseContext":{"statusCode":200,"executedVersion":"$LATEST"},"responsePayload":{"statusCode": 200, "body": "\"Hello from Lambda!\""}}
useful information

Now delete this destination 

go to configuration -> asynchronous invocation & enable SNS for DeadLetterQueue
you will receive an email from DLQ
// {}
No useful information for us but it let lambda know that there was failed invocation
---------------------------------------------------------------------------
LAMBDA DEPLOYMENT PACKAGE
when you paste code in lambda, lambda automatically creates a deployment package for you in .zip which includes your code and dependencies.

Other Method -> create deployment package yourself and upload zip file 
             -> limit is 50 mb
             -> if deployment package is greater than 50 mb 
             -> upload it to S3 in same region as u create your function
             -> then specify S3 object when u create your function 

Other Method -> Lambda Layers
             -> libraries, custon runtimes, etc 
             -> a layer can be used by multiple functions 
             -> helps reduce the size of deployment package 
             -> BEST PRACTICE
---------------------------------------------------------------------------
LAMBDA PERFORMANCE TUNING 
memory 128 mb to 10,240 mb
adding memory will improve function performance because with more memory, you get more cpu.
adding memory may reduce duration the function runs for
Steps:
DOWNLOADS CODE ---> CONFIGURE ---> STATIC INITIALIZATION ---> FUNCTION CODE
set ups execution   memory,         import libraries,sdks     tmp, re-use 
environment         runtime          (ADDS LATENCY)           execution env
                                                        for next function

How to optimize STATIC INITIALIZATION
three factors to reduce latency:
1- code - the amount of code that needs to run during initialization phase 
2- function package size 
3- performance - libraries/other services that require connections to be set up e.g. connections to S3 or database
e.g. dont import entire aws-sdk if your code can run on just one or two services 
instead of (aws-sdk), import (aws-sdk/clients/dynamodb)
---------------------------------------------------------------------------


API GATEWAYS (ADVANCED)

SOAP - legacy protocol - returns a response in XML format instead of JSON
        came out in 1990s - you can configure API Gateway as a SOAP web service passthrough - how?
        https://www.rubix.nl/blogs/how-configure-amazon-api-gatewaysoap-        webservice-passthrough-minutes
REST - Latest protocol

IMPORT APIs
You can use the API Gateway Import API feature to import an API from an
external definition file into API Gateway. Currently, the Import API feature supports Swagger v2.0 definition files. aka OpenAPI
With the Import API, you can either create a new API by submitting
a POST request that includes a Swagger definition in the payload and
endpoint configuration, or you can update an existing API by using a PUT
request that contains a Swagger definition in the payload. You can update
an API by overwriting it with a new definition, or merge a definition with an
existing API. You specify the options using a mode query parameter in the
request URL .
Import


API THROTTLING
By default, API Gateway limits the steady-state request rate to
10,000 requests per second (rps).
The maximum concurrent requests is 5000 requests across all
APIs within an AWS account.
If you go over 10,000 requests per second or 5000 concurrent
requests you will receive a 429 Too Many Request error
response.
API
Import API’s using Swagger 2.0 definition files
• API Gateway can be throttled
• Default limits are 10,000 RPS or 5000 concurrently
• You can configure API Gateway as a SOAP Webservice   
passthrough
--------------------------------------------------
API GATEWAY MOCK ENDPOINTS
Create, Test, Debug
backend is not ready yet but you want to test some new website features
e.g. cart,payment
allows team to continue development without depending on backend to be build
API GATEWAY RESPONSE - 
You definee the response 
status code and message 
forms the mock integration response 
---------------------------------------------------
API GATEWAY STAGEs 
references the lifecycle state of the API e.g. dev,prod 
Each stage can be associated with a different endpoint e.g. dev,prod
each stage has a unique invoke url e.g. 
https://dwncjrevn.execute-api.us-east-1.amazonaws.com/dev 
https://dwncjrevn.execute-api.us-east-1.amazonaws.com/prod
        API ID                                      Stage name

if we have 2 lambda functions, dev&prod, we can create API gateway with dev&prod stage 


LAB Creating Stages 
Create 2 functions stageDevevFunction,stageProdFunction with following code 
// export const handler = async (event) => {
//   // TODO implement
//   const response = {
//     statusCode: 200,
//     body: JSON.stringify('This is my Prod/Dev function'),
//   };
//   return response;
// };
goto API Gateway
BUILD REST API --> NewAPI & name=MyAPI -> Create API
ACTION->CREATE METHOD->"GET"->Lambda Function = ${stageVariables.lmbfunction}->
it gives you a command to run in cloudshell 
// aws lambda add-permission --function-name "arn:aws:lambda:us-east-1:965329023955:function:myprod/devfunction" --source-arn "arn:aws:execute-api:us-east-1:965329023955:nzxaisdv5m/*/GET/" --principal apigateway.amazonaws.com --statement-id 0e68dff5-42c2-4116-81f7-a26a4ae2a2bc --action lambda:InvokeFunction
save 
ACTION->DEPLOY API->newstage(test)
CREATE->prod 
STAGE VARIABLE->key=lmbfunction value=stageProdFunction
CREATE->dev
STAGE VARIABLE->key=lmbfunction value=stageDevFunction
-----------------------------------------------------
API RESPONSE TRANSFORMATIONS
AppFrontend->APIRequest->  APIGateway  ->APIRequest->AppBackend
                          modify Request

AppFrontend<-APIResponse<-  APIGateway  <-APIResponse<-AppBackend
                          modify Response

HTTP APIs:
parameter mapping is used to modify API requests and responses
we can change the Header, Query String, Request Path in API Request
we can change the Header, Status Code,               in API Response
-----------------------------------------------------
API GATEWAY CACHING:
CACHES your endpoints response (this reduces no. of calls made to endpoint)
TTL (when u enable caching, api gateway caches responses from endpoints for a specified TTL, default is 300 seconds)
API GATEWAY returns cached response to new requests, instead of making new request to endpoint. 
THIS REDUCES LATENCY

API GATEWAY THROTTLING is to prevent your API from being overwhelmed by too many requests
by-default, API Gateway limits the steady-state request rate to 10,000 requests per second,per region.
by-default, API Gateway limits the concurrent request to 5,000 across all APIs per second,per region.
if you exceed any of these limits, you get 429 ERROR (Too Many Requests)

Throttling Example 
5,000 requests in 1st millisecond 
5,000 requests evenly spread across 999 milliseconds
this is within limits of 10,000 req per second and 5,000 concurrent request
this will happen without any errors

------------------------------------------------------
X-Ray
X-Ray [Service Map] provides end-to-end view of API requests as they travel through your application
X-Ray can be integrated with EC2, ECS, Lambda, EB, SNS, SQS, DynamoDB, ELB, API Gateway, S3
X-Ray can be integrated with with your own application written in java, node.js, .net, go, ruby, python
X-Ray SDK automatically captures metadata for API calls made to AWS services using AWS SDK

Procedure:
Install X-Ray Agent on EC2 instance
Instrument your application using X-Ray SDK (sdk has libraries)
X-Ray sdk gathers informationfrom request and response headers, the code in your application and metadata about aws resources on which it runs and send this trace data to X-Ray e.g. HTTP requests, error codes, latency data

You need instrument(configure) both the X-Ray SDK and X-Ray Daemon on your systems
sdk sends data to daemon, which uploads them to X-Ray in batches

for docker container, install X-Ray daemon in its own docker container, and your application in its own container, all in same ECS cluster



---------------------------------------------------------------------------
You are a developer for a busy real estate company, and you want to enable other real estate agents to have the ability to show properties on your books, but skinned so that it looks like their own website. You decide the most efficient way to do this is to expose your API to the public using API Gateway. The project works well, but one of your competitors starts abusing this by sending your API tens of thousands of requests per second. This generates an HTTP 429 error. Each agent connects to your API using individual API keys. What actions can you take to stop this behavior?

Choose 2


Place an AWS Web Application Firewall (AWS WAF) in front of API Gateway and filter the requests


Deploy multiple API Gateways and give the agent access to another API Gateway


Use AWS Shield Advanced API protection to block the requests


Throttle the agent's API access using the individual API Keys

Good work!
AWS WAF helps protect your web applications or APIs against common web exploits that could impact availability, compromise security, or consume excessive resources.

To prevent your API from being overwhelmed by too many requests, Amazon API Gateway throttles requests to your API using the token bucket algorithm, where a token counts for a request. You can enable usage plans to restrict client request submissions to within specified request rates and quotas. This restricts the overall request submissions so that they don't go significantly past the account-level throttling limits in a Region. Amazon API Gateway provides Per-client throttling limits that are applied to clients that use API keys associated with your usage policy as client identifier.

