FEATURES:
The application is packaged so that you control the application and all associated resources, such as policies, security, and deployment.


bullet
Containers are portable and can be moved to different OS or hardware platforms, and through different environments such as development, testing/staging, pre-production, and production.


bullet
There are no time-out limits when running. This is useful for applications that run longer than 15 minutes or that need to initiate instantly when called.


bullet
Containers run without the startup latency of Lambda or Amazon EC2.


bullet
Containers have no size limit. They can be as large or as small as you need them to be.


bullet
Containers are useful when taking a large traditional application and breaking it down into small parts, or microservices, to make the application more scaleable and resilient. 





===============================================================
When to consider containers

For compute-intensive workloads
Applications that are compute intensive run better in a container environment. If you have a small application that runs under in 15 minutes but is compute intensive, consider using a container. Lambda is not the best fit for a heavily compute-intensive piece of code.

For large monolithic applications 
These are appropriate candidates to move to containers. Large monoliths that have many parts are very suitable applications to consider moving to containers. 
You can break apart applications and run them as independent components, called microservices, using containers to isolate processes.
By using microservices, you can break large applications into smaller, self-contained pieces. 
Segmenting a larger application means that updates can be applied on only specific parts. Because each part of the larger application resides in its own container, an update that might have affected files used by a different piece of the application is isolated to its own container.

With containers, you can do frequent updates by pushing out new containers, without the concern that one set of updates might break another part of the application. If you detect any issues, you have the flexibility to undo the change quickly.

When you need to scale quickly 
Containers can be built and taken down quickly, which means fast application deployment and scaling.

When you need to move your large application to the cloud without altering the code 

With containers, you can package entire applications and move them to the cloud without the need to make any code changes. 

Your application can be as large as you need it to be and can run as long as you require it to run.






When not to use containers

When applications need persistent data storage 
Containers can absolutely support persistent storage; however, it tends to be easier to containerize applications that don't require persistent storage. Persistent storage requirements increase the security and storage complexity and also make the containers less portable. If the container is moved, the storage needs to be reconfigured and secured.

Applications that have no state information and don't require complex persistent storage would be better candidates for using a container solution than an application with complex storage needs.


When applications have complex networking, routing, or security requirements
Containers are portable and can be moved through different environments (testing, staging, production). If the application requires a complex configuration for networking, routing, storage, and so on, the containers are much more challenging to move.
===============================================================
=     Auto Scaling Group 
=
=
= -----------------------------------------------------------
= |                       ECS CLUSTER                       |
= |    _____________________    _____________________       |
= |   |    EC2 Container    |  |   EC2 Container     |      |
= |   | task1 task2 service |  |  service1 service2  |      |
= |   |_____________________|  |_____________________|      |
= |---------------------------------------------------------|
=
=
===============================================================
Cluster = Multiple EC2 instances which will house docker containers
Task Definition = JSON file tht defines configuration of upto 10 containers
EC2 Container = EC2 Instances with mulriple Docker Containers
Tasks = one-off job ( just like BuildFile in EB)
Service = Long-running jobs (like ProcFile)
Container Agent = Binary on each EC2 which monitors, start & stop tasks 

CLUSTER TYPES: 
1-ECS Clusters
2-Fargate (serverless and you can create empty cluster)

OPTIONS:
Spot or on Demand
EC2 Instance Type 
No. of Instances 
EBS Storage Volumes
EC2 can be aws Linux 1 or 2
VPC, IAM Role, CloudWatch, Key Pair , SSH into container is not rec. by aws




==========================================
IAM
"ecsInstanceRole" with policy:
AmazonEC2ContainerServiceforEC2Role
==========================================
Task execution IAM role
This role is required by tasks to pull container images and publish container logs to Amazon CloudWatch on your behalf. If you do not have the ecsTaskExecutionRole already, we can create one for you.

Use cases for other AWS services:

Elastic Container Service
Allows ECS to create and manage AWS resources on your behalf.


---->Elastic Container Service Task
Allows ECS tasks to call AWS services on your behalf.

AmazonECSTaskExecutionRolePolicy
===========================================
IAM -> CloudShell
aws iam create-service-linked-role --aws-service-name ecs.amazonaws.com
===========================================
IAM -> CloudShell
aws iam create-service-linked-role --aws-service-name autoscaling.amazonaws.com
===========================================
IAM
'ECS CodeDeploy Role: Before you can use the CodeDeploy blue/green deployment type with Amazon ECS, the CodeDeploy service needs permissions to update your Amazon ECS service on your behalf. These permissions are provided by the CodeDeploy IAM role.

To create the ecsCodeDeployRole IAM role

Open the IAM console 
In the navigation pane, choose Roles, Create role.
Choose the AWS service role type, and then choose CodeDeploy.
Choose the CodeDeploy use case and then Next: Permissions.
For Role Name, type ecsCodeDeployRole and choose Create role.
Open ecsCodeDeployRole` role again from IAM console , to add the required additional permissions.
Choose Attach policies.
To narrow the available policies to attach, for Filter, type AWSCodeDeployRoleForECS
Check the box to the left of the AWS managed policy and choose Attach policy and Update.'
===========================================
Error in Creating Task Definition
IAM
IAM Create Policy and attach it to Rupert
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "*"
        }
    ]
}
=============================================
Create Cluster
Create Task Definition = JSON file tht defines configuration of upto 10 containers
Create Container
Create Service on the Container
------------------------------------------------------------

FARGATE 
you have VPC and subnet in Fargate (serverless) too
Same as EC2, apply Security Group at Task Level
You can apply IAM role at Task level too


                FARGATE         vs          LAMBDA      
Cold Starts     yes(shorter)                yes 
Duration        As long as you want         15 min (max)
Memory          upto 30gb                   upto 3gb 
Containers      you provide ur own cont     limited to standard cont 
Integrations    More Manual Labour          seamless integration with aws
Pricing         atleast 1 min and every     pay per 100ms
                additional second   


Launch your Fargate Tasks into subnets
Under the hood •
• We create an Elastic Network Interface (ENI)
• The ENI is allocated a private IP from your subnet
• The ENI is attached to your task
• Your task now has a private IP from your subnet!

You can assign public IPs to your tasks
Configure security groups to control inbound & outbound traffic

Docker images are composed of layers
The topmost layer is the "writable" layer to capture file changes made by the running container
IO-GB layer storage available per task, across all containers, including image layers 
Writes are not visible across containers


Writable Layer
Image Layers
Container 1



-------------------------------------
IAM PERMISSIONS:

1-Cluster Permissions:
Control who can launch/describe tasks in your cluster 

2-Application(Task) Permissions:
Allows your application containers to access AWS resources securely

3-Housekeeping Permissions:(AWS Managed)
Allows us to perform housekeeping activities around your task:

Housekeeping Permissions
We (AWS) need certain permissions in your account to bootstrap your task and keep itrunning.
Execution Role gives us permissions for:
    • ECR Image Pull
    • Pushing CloudWatch Logs
ECS Service Linked Role gives us permissions for:
    ENI Management
    ELB Target Registration/Deregistration targets into Elastic Load Balancing
=========================================================================

Managed Service Discovery for ECS: AWS Managed Integration wit Route 53
• Service registry:
    • Predictable Names for services
    • Auto updated with latest, healthy IP, port
• High availability, high scale
• Extensible: Flexible boundaries for auto discovery
- - - - - - - - - - - - - - - - - - - - - - - - -  - - - - - - - - - -  - -
Amazon Route 53 Auto Naming Provides Service Registry:
Amazon Route 53 provides APIs to create
• Namespace
• CNAME per service autoname
• A records per task IP
• SRV records per task IP + port
- - - - - - - - - - - - - - - - - - - - - - - - -  - - - - - - - - - -  - -
ECS Schedules & Places Service Endpoints:
ECS Scheduler updates on:
• Service scaling
    • Task registrations
    • Task de-registrations
. Task health
• Scheduling / Placement changes
• ECS instance changes
ECS maintains latest state of the dynamic environment in Service Registry
============================================================================
CI/CD for our tasks in AWS Fargate
[ec2-user@ip-19-e-2-65 FargateDemo] aws ecs create-cluster --cluster-name ptctshare --regton ap-southeast-2
[ec2-user@ip-19-e-2-65 FargateDemo]S nano task_definition.json
[ec2-user@ip-19-e-2-65 FargateDemo]S aws ecs register-task-definition \
                                > --cli-input-json file://task_definition.json
                                > -- region ap-southeast-2 --query 'taskDefinition. taskDefinitionArn'
[ec2-user@ip-19-e-2-65 FargateDemo]S nano service.json
[ec2-user@ip-19-e-2-65 FargateDemo]S aws ecs create-service --cli-input-json file:/ /service.json
[ec2-user@ip-19-e-2-65 FargateDemo]S aws application-autoscaling register-scalable-target \
                                --resource-id service/pictshare/pictshare --service-namespace ecs \
                                --scalabte-dimension ecs:service:DesiredCount --min-capacity 1 --max-capacity 20 \
                                --role-arn arn:aws:.......
[ec2-user@ip-19-e-2-65 FargateDemo]S nano Scale-Out.json
[ec2-user@ip-19-e-2-65 FargateDemo]S aws application-autoscaling put-scaling-policy --cli-input-json file:/ /scale-out.json

[ec2-user@ip-19-e-2-65 FargateDemo]S aws codecommit create-repository --repository-name pictshare
[ec2-user@ip-1@-@-2-65 FargateDemo]$ aws codebuild create-project \
> --name "pictshare" \
> --description "Build project for Pictshare" \
> --source type="CODEPIPELINE"\
> --service-role "arn:aws:iam:::role/CodeBuIldExecutionRole" \
> --environment type="LINUX_CONTAINER", \
> environmentVariables=" [{name=AWS_DEFAULT_REGION.value='ap-southeast-2'
{name=REPOSITORY URI.value=arn:aws:codecommit:ap-southeast-243543636:pictshare}]" \
--artifacts type="CODEPIPELINE"

[ec2-user@ip-I@-@-2-65 FargateDemo]$ nano pipeline structure.json
[ec2-user@ip-1@-@-2-65 FargateDemo]$ aws codepipelfne create-pipeline \
--pipeline file://pipeline_structure.json

[ec2-user@ip-1@-@-2-65 FargateDemo]$ nano event.json
[ec2-user@ip-1@-@-2-65 FargateDemo]$ aws events put-rule \
> --cli-input-json file://event_put_rule.json

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  - - - - - - - -  - - - -
Scale-Out.json
"PolicyName":
"ServiceNamespace": "ecs" ,
"Resourceld": "service/pictshare/pictshare",
"ScalableDimension": "ecs:service:Desi redCount" ,
"Policy Type": "Target TrackingScaling"
"Target TrackingScalingPolicyConfiguration": {
    "TargetValue": 50
            "PredefinedMetricSpecification" : {
            "PredefinedMetricType": "ECSServiceAverageCPUUtilization"
        },
        "ScaleOutCooldown". 5
        "ScalelnCooldown": 5
        "DisableScaleIn" : false
    }
}

event.json
"Name" : "CodeCommitRulePictshare",
"EventPattern" : "[\"source\": [ \"aws.codecommit\" ] .\"detail-type\": [\"CodeCommit Repository State Change\"
"State": "ENABLED"
"
============================================================================
============================================================================
============================================================================
============================================================================
In Amazon ECS, the machine that runs the containers is an EC2 instance that has an ECS agent installed and configured to run and manage your containers. This instance is called a container instance. In Amazon EKS, the machine that runs the containers is called a worker node or Kubernetes node. 

An ECS container is called a task. An EKS container is called a pod.


Amazon ECS runs on AWS native technology. Amazon EKS runs on Kubernetes. 

============================================================================
As the AWS solutions architect, you need to explore whether Amazon ECS is the right choice to build sophisticated application architectures on a microservices model.

Which of the following is true for Amazon ECS? (Select THREE)

```Amazon ECS provides service discovery for a microservice architecture.
```A cluster may contain a mix of tasks hosted on AWS Fargate, Amazon EC2 instances, or external instances.
```Amazon ECS manages your cluster resources for all launch types.
Easier to manage since your entire application need to be on a single task definition.
Amazon ECS has built-in security; all of the images are stored in a container registry that is only accessible through HTTPS.
Amazon ECS supports multi-cloud integration.

============================================================================
For migrating Windows workloads with the top priority of convenience and ease, the best option among the provided AWS managed services would be:

Amazon ECS (Elastic Container Service) with AWS Fargate

Amazon ECS is a fully managed container orchestration service, and when used in conjunction with AWS Fargate, it allows you to run containers without managing the underlying infrastructure. This means you can focus on deploying and managing your Windows workloads without worrying about server management tasks.

AWS Fargate is a serverless compute engine for containers that works seamlessly with Amazon ECS. It removes the need to manage the underlying infrastructure, allowing you to concentrate on deploying your applications.

Together, Amazon ECS and AWS Fargate provide a convenient and easy way to migrate and manage containerized Windows workloads on AWS.
=======================================================================
You are running a CI/CD pipeline using CodePipeline to deploy containers to Elastic Kubernetes Service (EKS). Container images are stored in Elastic Container Registry (ECR), for deployment to EKS. Before the image is deployed, you want to run a security check on the image, with the ability to fail the pipeline if the security check fails. How do you do this in CodePipeline?

Create a test action in the deployment stage to perform security scanning prior to deploying the image.

This is not the AWS recommended way of adding a test that needs to happen prior to a deployment.

Selected
Build the container image locally and perform a security scan before beginning the CD/CD pipeline. Push any changes to the source code repository.

"Create a test stage with a test action that will happen before the deployment stage.
CodePipeline allows you to create a test stage with a test action prior to the deployment stage.
Reference: Add a CodeBuild Test Action to a Pipeline"

Create a test action in the deployment stage to perform security scanning after deploying the image.


========================================================================
D:\devops\4-AWS\Functions\ECRapp
0 - Instal DOCKER in Cloud9
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ ./install_scripts/install_docker.sh 
1 - SET ENVIRONMENT VARIABLES
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ region=$(aws configure get region)
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ repo_name="my_app"
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ region=${region:-us-east-1}
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ repo_name="my_app"
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ account=${aws sts get-caller-identity --query Account --output text}
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ fullname="${account}.dkr.ecr.${region}.amazonaws.com/${repo_name}:latest"
2 - CREATE REPOSITORY
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ aws ecr create-repository --repository-name "${repo_name}"
{
    "repository": {
        "repositoryArn": "arn:aws:ecr:us-east-1:712089354051:repository/my_app",
        "registryId": "712089354051",
        "repositoryName": "my_app",
        "repositoryUri": "712089354051.dkr.ecr.us-east-1.amazonaws.com/my_app",
        "createdAt": "2023-10-06T13:58:08+00:00",
        "imageTagMutability": "MUTABLE",
        "imageScanningConfiguration": {
            "scanOnPush": false
        },
        "encryptionConfiguration": {
            "encryptionType": "AES256"
        }
    }
}
3- AUTHENTICATE DOCKER with ECR
==>  aws ecr get-login-password —region ${region} | docker login --usemame AWS --password-stdin ${fullname}
--    The AWS CLI "get-login-password" command authenticates Docker to an Amazon ECR registry.

4- Create Build
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker build -t ${repo_name} .
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker images
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker tag ${repo_name} ${fullname}
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker push ${fullname}


OPEN Security Group Port 8443 for your VPC 0.0.0.0/0
OPEN ECS
ENTER Cluster 
CREATE Task Definition 
CREATE Task --> 
in Networking -> attach proper VPC and editted Security Group
in Task overrides -> use ecsTaskExecutionRole with AmazonECSTaskExecutionRolePolicy
browser -> http://44.211.180.156:8443/

"
==============================================================================================================

A developer is building an application that will be hosted in ECS and must be configured to run tasks and services using the Fargate launch type. The application will have four different tasks, each of which will access different AWS resources than the others.

Which of the following is the MOST efficient solution that can provide your application in ECS access to the required AWS resources?

Create 4 different IAM Roles with the required permissions and attach them to each of the 4 ECS tasks.```````
Create 4 different Container Instance IAM Roles with the required permissions and attach them to each of the 4 ECS tasks.
Create 4 different Service-Linked Roles with the required permissions and attach them to each of the 4 ECS tasks.
Create an IAM Group with all the required permissions and attach them to each of the 4 ECS tasks.
Incorrect
By default, IAM users don’t have permission to create or modify Amazon ECS resources or perform tasks using the Amazon ECS API. This means that they also can’t do so using the Amazon ECS console or the AWS CLI. To allow IAM users to create or modify resources and perform tasks, you must create IAM policies. Policies grant IAM users permission to use specific resources and API actions. Then, attach those policies to the IAM users or groups that require those permissions.




When you attach a policy to a user or group of users, it allows or denies the users permission to perform the specified tasks on the specified resources. Likewise, Amazon ECS container instances make calls to the Amazon ECS and Amazon EC2 APIs on your behalf, so they need to authenticate with your credentials. This authentication is accomplished by creating an IAM role for your container instances and associating that role with your container instances when you launch them.

If you use an Elastic Load Balancing load balancer with your Amazon ECS services, calls to the Amazon EC2 and Elastic Load Balancing APIs are made on your behalf to register and deregister container instances with your load balancers.

Hence, the most suitable solution in this scenario is: Create 4 different IAM Roles with the required permissions and attach them to each of the 4 ECS tasks.

The option that says: Creating an IAM Group with all the required permissions and attaching them to each of the 4 ECS tasks is incorrect because you cannot directly attach an IAM Group to an ECS Task. Attaching an IAM Role is a more suitable solution in this scenario and not an IAM Group.

The option that says: Creating 4 different Container Instance IAM Roles with the required permissions and attaching them to each of the 4 ECS tasks is incorrect because a Container Instance IAM Role only applies if you are using the EC2 launch type. Take note that the scenario says that the application will be using a Fargate launch type.

The option that says: Creating 4 different Service-Linked Roles with the required permissions and attaching them to each of the 4 ECS tasks is incorrect because a service-linked role is a unique type of IAM role that is linked directly to Amazon ECS itself, not on the ECS task. Service-linked roles are predefined by Amazon ECS and include all the permissions that the service requires to call other AWS services on your behalf.

 =================================================================================================================
 A developer is designing an application which will be hosted in ECS and uses an EC2 launch type. You need to group your container instances by certain attributes such as Availability Zone, instance type, or custom metadata. After you have defined a group of container instances, you will need to customize Amazon ECS to place tasks on container instances based on the group you specified.

Which of the following ECS features provides you with expressions that you can use to group container instances by a specific attribute?

Task Placement Constraints
Task Groups
Task Placement Strategies
Cluster Query Language`````````````````````
Incorrect
When a task that uses the EC2 launch type is launched, Amazon ECS must determine where to place the task based on the requirements specified in the task definition, such as CPU and memory. Similarly, when you scale down the task count, Amazon ECS must determine which tasks to terminate. You can apply task placement strategies and constraints to customize how Amazon ECS places and terminates tasks. Task placement strategies and constraints are not supported for tasks using the Fargate launch type. By default, Fargate tasks are spread across Availability Zones.



Cluster queries are expressions that enable you to group objects. For example, you can group container instances by attributes such as Availability Zone, instance type, or custom metadata. You can add custom metadata to your container instances, known as attributes. Each attribute has a name and an optional string value. You can use the built-in attributes provided by Amazon ECS or define custom attributes.

After you have defined a group of container instances, you can customize Amazon ECS to place tasks on container instances based on group. Running tasks manually is ideal in certain situations. For example, suppose that you are developing a task but you are not ready to deploy this task with the service scheduler. Perhaps your task is a one-time or periodic batch job that does not make sense to keep running or restart when it finishes.

Hence, the correct ECS feature which provides you with expressions that you can use to group container instances by a specific attribute is Cluster Query Language.

Task Group is incorrect because this is just a set of related tasks. This does not provide expressions that enable you to group objects. All tasks with the same task group name are considered as a set when performing spread placement.

Task Placement Constraint is incorrect because it is just a rule that is considered during task placement. Although it uses cluster queries when you are placing tasks on container instances based on a specific expression, it does not provide the actual expressions which are used to group those container instances.

Task Placement Strategies is incorrect because this is just an algorithm for selecting instances for task placement or tasks for termination.

 

============================================================================================================
	
A company wants to know how its monolithic application will perform on a microservice architecture. The Lead Developer has deployed the application on Amazon ECS using the EC2 launch type. He terminated the container instance after testing; however, the container instance still appears as a resource in the ECS cluster.

What is the possible cause of this?

(view)	1	0	1	00:01:01	
 When a container instance is terminated in the running state, the container instance is not automatically deregistered from the cluster.
 When a container instance is terminated in the stopped state, the container instance is not automatically deregistered from the cluster.````````````````````````
 After terminating the container instance in the running state, the container instance must be manually deregistered in the Amazon ECS Console.
 After terminating the container instance in the stopped state, the container instance must be manually deregistered in the Amazon EC2 Console since it was launched using the EC2 launch type.
If you terminate a container instance in the RUNNING state, that container instance is automatically removed or deregistered from the cluster. However, if you terminate a container instance in the STOPPED state, that container instance isn't automatically removed from the cluster.

To deregister your container instance from the cluster, you should deregister it after terminating it in the STOPPED state by using the Amazon ECS Console or AWS Command Line Interface. The deregistered container instance will no longer appear as a resource in your Amazon ECS cluster.