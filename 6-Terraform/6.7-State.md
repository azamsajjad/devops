7	Implement and maintain state
7a	Describe default local backend
7b	Describe state locking
7c	Handle backend and cloud integration authentication methods
7d	Differentiate remote state backend options
7e	Manage resource drift and Terraform state
7f	Describe backend block and cloud integration in configuration
7g	Understand secret management in state files

-----------------------------------------------------
----------------------------------------
# Terraform State
What is State?
A particular condition of cloud resources at a specific time.
eg. We expect there to be a Virtual Machine running CentOS on AWS with a compute type of t2.micro.
How does Terraform preserve state?
When you provision infrastructure via Terraform it will create a state file named 
terraform.tfstate
This state file is a JSON data structure with a one-to-one mapping from resource instances to remote objects

> terraform state list 
List resources in the state
> terraform state mv <-exam>
Move an item in the state
terraform state mv allows you to:
• rename existing resources
• move a resource into a module
• move a module into a module
If you were to just rename a resource or move it to another module and run terraform
apply Terraform will destroy and create the resource. State mv allows you to just change
the reference so you can avoid a create and destroy action
- RENAME
terraform state mv packet_device.worker packet_device.helper
- MOVE RESOURCE INTO MODULE
terraform state mv packet_devtce.worker module.worker.packet_devtce.worker
- MOVE MODULE INTO A MODULE
terraform state mv module. app module.parent.modute.app

> terraform state pull
Pull current remote state and output to stdout
> terraform state push
Update remote state from a local state
> terraform state replace-provider
Replace provider in the state
> terraform state rm
Remove instances from the state
> terraform state show
Show a resource in the state


-------------------------------------------------------
----------------------------------------
## Drift
>How to detect configuration drift?
A compliance tool that can detect misconfiguration eg. AWS Config, Azure Policies, *GCP Security Health Analytics
Built-in support for drift detection eg. AWS CloudFormation Drift Detection
Storing the expected state eg. Terraform state files
How to correct configuration drift?
A compliance tool that can remediate (correct) misconfiguration e.g. AWS Config
• Terraform refresh and plan commands

Manually correcting the configuration (not recommended)
• Tearing down and setting up the infrastructure again
How to prevent configuration drift?
• Immutable infrastructure, always create and destroy, never reuse, Blue, Green deployment strategy.
• Servers are never modified after they are deployed
Baking AMI images or containers via AWS Image Builder or HashiCorp Packer, or a build server eg. GCP Cloud Run
Using GitOps to version control our laC, and peer review every single via Pull Requests change to infrastructure

### We can resolve Drift in three ways in Terraform:
---------------------
> Replacing Resources / Taint (DEPRECATED in v 0.152)
When a resource has become damaged or degraded that cannot be detected by Terraform we can use the <replace flag>
        <terraform apply -replace="aws_instance.example[0]">
        one resource at a time
Terraform Taint is used to mark a resource for replacement, the next time you run apply.
Why would want to mark a resource for replacement?
terraform taint aws_instance.my_web_app
A cloud resource can become degraded or damaged and you
want to return the expected resource to a healthy state
---------------------
> Importing Resources
When an approved manual addition of resource needs to be added to our state file We use the <import command>.
        <terraform import aws_instance.example i-abcd1234>
                                resource address      id
Steps:
1- define a placeholder for your imported resource in config files
2- you can leave the body blank and fill it after importing it
3- proceed with importing with above command

The command can only import one resource at a time.
Not all resources are importable, you need to check the bottom of resource documentation for suppc
---------------
> Refresh State
When an approved manual configuration of a resource has changed or removed
We use the <refresh-only flag> to reflect the changes in our state file

The terraform refresh command reads the current settings from all managed remote objects and updates the Terraform state to match.

The terraform refresh command is an alias for the refresh only and auto approve

<terraform refresh>  DEPRECATED
<terraform apply -refresh-only --auto-approve>


Terraform refresh will not modify your real remote objects, but it will modify the Terraform state.
Terraform refresh has been deprecated and with the refresh-only flag because it was not safe since it did not give you an opportunity to review proposed changes before updating state file

The —refresh-only flag for terraform plan or apply allows you to refresh and update your state file without making changes to your remote infrastructure.

> Scenario
Scenario
Imagine you create a terraform script that deploys a Virtual Machine on AWS You ask an engineer to terminate the server, and instead of updating the terraform script they mistakenly terminate the server via the AWS Console.
2 Options as Next Steps:
1) Either you run <terraform apply>   or
2) <terraform apply -refresh-only>

1) Either you run <terraform apply>
        Terraform will notice that the VM is missing
        Terraform will propose to create a new VM
        The State File is correct
        Changes the infrastructure to match state file
2) <terraform apply -refresh-only>
Terraform will notice that the VM you provisioned is missing.
With the refresh-only flag that the missing VM is intentional
Terraform will propose to delete VM from the state file
The State File is wrong
Changes the state file to match infrastructure
--------------------------------------------
# BACKEND
Each Terraform configuration can specify a backend, which defines where and how operations are performed, where state snapshots are stored
Terraform's backends are divided into two types:
> Standard backends
• only store state
• does not perform terraform operations eg. Terraform apply
• To perform operations you use the CLI on your local machine
• third-party backends are Standard backends e.g. AWS S3
> Enhanced backends
• can both store state
• can perform terraform operations
> enhanced backends are subdivided further:
    • local — files and data are stored on the local machine executing terraform commands
    • remote —files and data are stored in the cloud eg. Terraform Cloud


## Standard Backends S3
Configuring a standard backend does not require a Terraform Cloud account or workspace
The backup of a state file will reside on your loca machine.
> tfstate file in S3 / gcs / kubernetes / azurerm / etc
it is not good practice to store tfstate file on github, due to general pull and push error, your configuration can get misconfigured

best practice is to store tfstate file in Terraform Backend, a centrally managed remote location from where all developers can work on the same tfstate file. 

you will not store tfstate file on your local machine
> pre-req
> awscli should be pre-installed on your system
general practice is to store it in AWS S3
1- free tier
2- provides locking mechanism

devops@T480:~/terraform/resource/5-backendS3$ terraform init

Initializing the backend...

Successfully configured the backend "s3"! Terraform will automatically
use this backend unless the backend configuration changes.



even with workspaces, env/ folder is created in S3 with tfstate files


> fetch updated statefile data
terraform state pull

terraform state push - not a good practice
you can override your teammates state changes
> to migrate backend:
  -migrate-state          Reconfigure a backend, and attempt to migrate any existing state.

comment out backend code and run
> terraform init -migrate-state
local working directory now has tfstate file


> Locking Mechanism
if 2 developers run terraform apply simultaneously
there will be a problem

solution - create a dynamodb table which will lock the state temporarily when any apply/destroy command is in progress. and it will not allow any other apply command from someone else to be run

make a dynamoDB table
> LockID as partition key


terraform {
    backend "s3" {
        bucket = "tfstate-reason"
        region = "us-east-1"
        key = "terraform.tfstate"
        dynamodb_table = "tfstate-reason-lock"
    }
}

## Enhanced Backends - Local
The local backend:
• stores state on the local filesystem
• locks that state using system APIs
• performs operations locally

1) By default, you are using the
backend state when you
have no specified backend
terraform {
}

2) You specific the backend with argument
local, and you can change the path to the
local file and working_directory
terraform {
    backend "local" {
        path = "relative/path/to/terraform.tfstate"
    }
}


3) You can set a backend to reference
another state file so you can read its
outputted values.
This is way of <cross-referencing stacks>

data "terraform_remote_state" "networking" {
    backend = "local"
    config = {
        path = "${path.module}/networking/terraform.tfstate"
    }
}

## Enhanced Backends - Remote 
A Remote backend uses the Terraform platform which is either:
• Terraform Cloud
• Terraform Enterprise
With a remote backend when terraform apply is performed via the CLI
The Terraform Cloud <Run Environment> is responsible for executing the operation

~~~sh
important point:
Because the Terraform Cloud Run Environment is executing the
command. Your provider credentials need to be configured in
Environment Variables in Terraform Cloud
~~~

When using a remote backend you need to set a Terraform Cloud Workspaces by name or prefix

1) by NAME - ou can set a single workspace via name
terraform {
    backend "remote" {
        hostname = "app.terraform.io"
        organization = "company"
        workspaces {
            name = "my-app-prod"
        }
    }
}


2) by PREFIX - You can set multiple workspaces via prefix
terraform {
    backend "remote" {
        hostname = "app.terraform.io"
        organization = "company"
        workspaces {
            prefix = "my-app-"
        }
    }
}
On terraform apply you will have to
choose whict workspace you want
to apply the operation

2) for Terraform Cloud 
When using Terraform Cloud as a remote backend state you should instead use the cloud block to configure its usage.
terraform {
    cloud {
        hostname = "app.terraform.io"
        organization = "company"
        workspaces {
            prefix = "my-app-"
        }
    }
}

## Backend Initialization
The <backend-config> flag for terraform init can be used for partial backend configuration
In situations where the backend settings are dynamic or sensitive and so cannot be statically specified in the configuration file.

main.tf
terraform {
    required_version = "~> 0.12.0"
    backend "remote" {}
}

backend.hcl
workspaces = {
    name = "wordspaces"
}
hostname = "app.terraform.io"
organization = "company"

terraform init -backend-config=backend.hcl

## CROSS_REFERENCING STACKS   ---- VERY IMP
## terraform_remote_state

terraform_remote_state data source retrieves the root module output values from another Terraform configuration, using the latest state snapshot from the remote backend.
1) Remote Backend
~~~sh
data "terraform_remote_state" "vpc" {
    backend = "remote"
    config = {
        organization = "hashicorp"
        workspaces = {
            name = "vpc-prod"
        }
    }
}
resource "aws_instance" "web" {
    subnet_id = "data.terraform_remote_state.vpc.outputs.subnet_id"
}
~~~
2) Local Backend

~~~sh
data "terraform_remote_state" "vpc" {
    backend = "local"
    config = {
        path = ....
    }
}

resource "aws_instance" "web" {
    subnet_id = data.terraform_remote_state.vpc.outputs.subnet_id
}
~~~
Only the root-level output values from the remote state
snapshot are exposed
Resource data and output values from nested modules are
not accessible
To make a nested module output value accessible as a root
module output value, you must explicitly configure a
passthrough in the root module
~~~sh
module "app" {
    source = "..."
}
output "app_value" {
    value = module.app.example
}
~~~


## Alternative to terraform_remote_state

terraform_remote_state only exposes output values, its user must have access to the entire state snapshot, which often includes some sensitive information.

It recommend explicitly publishing data for external consumption to a separate location instead of accessing it via remote state

~~~sh
data "awS_s3_bucket" "selected" {
    bucket = "bucket.test.com"
}
data "aws_route53_zone" "test_zone" {
    name = "test.com."
}
resource "aws_route53_record" "example" {
    zone_id = "${data.aws_route53_zone.test_zone.id}"
    name = "bucket"
    type = "A"
    alias {
        name = "${data.aws_s3_bucket.selected.website_domain}"
        zone_id = "${data.aws_s3_bucket.selected.hosted_zone_id}"
    }
}
~~~

## State Locking
Terraform will lock your state for all operations that could write state.
This prevents others from acquiring the lock and potentially corrupting your state
State locking happens automatically on all operations that could write state
You won't see any message that it is happening. If state locking fails

> Disabling Locking
You can disable state locking for most commands
with the `-lock flag` but it is not recommended

> Force Unlock
Terraform has a `force-unlock command` to manually unlock the state if unlocking failed.
If you unlock the state when someone else is holding the lock it could cause multiple writers.
Force unlock should only be used to unlock your own lock in the situation where automatic unlocking failed.

To protect you, the force-unlock command requires a unique lock ID 
• Terraform will output this lock ID if unlocking fails

<terraform force-unlock 1941a539b-ff25-76ef-92d-547ab37b24d
-force>




## Protecting Sensitive Data

Terraform State file can contain sensitive data eg. long-lived AWS Credential and is a possible attack vector for malicious actors.

> Local State
When using local backend, state is stored in plain-text JSON files.
• You need to be careful you don't share this state file with anyone
• You need to be careful you don't commit this file to your git repository
> Remote State with Terraform Cloud
When using the Terraform Cloud remote backend:
That state file is held in memory and is not persisted to disk
The state file is encrypted-at-rest
The state file is encrypted-in-transit

> Terraform Enterprise
With Terraform Enterprise you have detailed audit logging for tamper evidence

> Remote State with Third-Party Storage
You can store state with various third-party backends.
You need to carefully review your backends capabilities to determine if will meet your security and compliance requirements.
Some backends are not by default as secure as they could be:
• eg. With AWS S3 you have to ensure encryption and versioning is turned on, you need to create a custom trail for data events


## State Manipulation
use cases:
1) when upgrading between versions
2) when you ewant to rename a resource in terraform without recreating it
3) when you changed a key in a for_each, but you dont want to recreate the resources
4) change position of a resource in a list (resource[0], resource[1],...)
5) when you want to stop managing a resource, but you dont want to destroy the resource (terraform state rm)
6) when you want to show the attributes in the state of a resource (terraform state show)


resource "aws_ebs_volume" "example" {   <--------------OLD NAME>
resource "aws_ebs_volume" "example2" {
    availability_zone = "eu-west-1a"
    size = 8
    tags = {for k, v in merge({ Name = "Myvolume" }, var.project_tags): k => lower(v)}
}                      #<-------------------------input-------------->:  <---output--->


azams@eurusvm:~/dev/terraform/udemy/loopsFunctions$ terraform apply
aws_ebs_volume.example: Refreshing state... [id=vol-04ca887d6377ecd09]
aws_security_group.sg_example2: Refreshing state... [id=sg-0307f3534863b04c7]
aws_security_group.sg_example: Refreshing state... [id=sg-0e0025c45509ae872]

Terraform used the selected providers to generate the following execution plan. Resource actions
are indicated with the following symbols:
  + create
  ~ update in-place
  - destroy

Terraform will perform the following actions:

  # aws_ebs_volume.example will be destroyed
  # (because aws_ebs_volume.example is not in configuration)
  - resource "aws_ebs_volume" "example" {
      - arn                  = "arn:aws:ec2:eu-west-1:058264510430:volume/vol-04ca887d6377ecd09" -> null
      - availability_zone    = "eu-west-1a" -> null
      - encrypted            = false -> null
      - final_snapshot       = false -> null
      - id                   = "vol-04ca887d6377ecd09" -> null
      - iops                 = 100 -> null
      - multi_attach_enabled = false -> null
      - size                 = 8 -> null
      - tags                 = {
          - "Component"   = "frontend"
          - "Environment" = "production"
          - "Name"        = "myvolume"
        } -> null
      - tags_all             = {
          - "Component"   = "frontend"
          - "Environment" = "production"
          - "Name"        = "myvolume"
        } -> null
      - throughput           = 0 -> null
      - type                 = "gp2" -> null
    }

  # aws_ebs_volume.example2 will be created
  + resource "aws_ebs_volume" "example2" {
      + arn               = (known after apply)
      + availability_zone = "eu-west-1a"
      + encrypted         = (known after apply)
      + final_snapshot    = false
      + id                = (known after apply)
      + iops              = (known after apply)
      + kms_key_id        = (known after apply)
      + size              = 8
      + snapshot_id       = (known after apply)
      + tags              = {
          + "Component"   = "frontend"
          + "Environment" = "production"
          + "Name"        = "myvolume"
        }
      + tags_all          = {
          + "Component"   = "frontend"
          + "Environment" = "production"
          + "Name"        = "myvolume"
        }
      + throughput        = (known after apply)
      + type              = (known after apply)
    }


## SOLUTION - terraform state mv <RESOURCE>

azams@eurusvm:~/dev/terraform/udemy/loopsFunctions$ terraform state mv aws_ebs_volume.example aws_eb
s_volume.example2
Move "aws_ebs_volume.example" to "aws_ebs_volume.example2"
Successfully moved 1 object(s).


if you want to remove a resource from terraform project

use


## terraform state rm <RESOURCE>
> terraform state rm aws_ebs_volume.example2
azams@eurusvm:~/dev/terraform/udemy/loopsFunctions$ terraform state rm aws_ebs_volume.example2
Removed aws_ebs_volume.example2
Successfully removed 1 resource instance(s).
it will still exist on aws, but you wont manage it by terraform

if you change your mind : -

## terraform import <RESOURCE> <Name/ID>
azams@eurusvm:~/dev/terraform/udemy/loopsFunctions$ terraform import aws_ebs_volume.example2 vol-04ca887d6377ecd09
aws_ebs_volume.example2: Importing from ID "vol-04ca887d6377ecd09"...
aws_ebs_volume.example2: Import prepared!
  Prepared aws_ebs_volume for import
aws_ebs_volume.example2: Refreshing state... [id=vol-04ca887d6377ecd09]

Import successful!

The resources that were imported are shown above. These resources are now in
your Terraform state and will henceforth be managed by Terraform.